{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n",
      "2022-11-30 23:54:07,628\tWARNING algorithm.py:2531 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-11-30 23:54:07,629\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=9 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 445.\n",
      "2022-11-30 23:54:10,151\tINFO worker.py:1528 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7940)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7941)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7938)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7944)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7936)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7943)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7934)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7937)\u001b[0m   import distutils.spawn\n",
      "\u001b[2m\u001b[36m(pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=7942)\u001b[0m   import distutils.spawn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8231)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\u001b[2m\u001b[36m(pid=8231)\u001b[0m   import distutils.spawn\n",
      "2022-11-30 23:54:18,705\tINFO trainable.py:164 -- Trainable.setup took 11.078 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-11-30 23:54:18,707\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=8231)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8231)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8231)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.515109648371256, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.885444407309254, 'policy_loss': -0.01844104374158046, 'vf_loss': 9.903408999084144, 'vf_explained_var': -0.019987816195334157, 'kl': 0.0023822404338313024, 'entropy': 0.6643356934670479, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 4005, 'num_env_steps_trained': 4005, 'num_agent_steps_sampled': 4005, 'num_agent_steps_trained': 4005}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 4005, 'num_agent_steps_trained': 4005, 'num_env_steps_sampled': 4005, 'num_env_steps_trained': 4005, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 4005, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 4005, 'timers': {'training_iteration_time_ms': 5682.314, 'load_time_ms': 0.828, 'load_throughput': 4839581.538, 'learn_time_ms': 4371.69, 'learn_throughput': 916.122, 'synch_weights_time_ms': 2.877}, 'counters': {'num_env_steps_sampled': 4005, 'num_env_steps_trained': 4005, 'num_agent_steps_sampled': 4005, 'num_agent_steps_trained': 4005}, 'done': False, 'episodes_total': 0, 'training_iteration': 1, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-24', 'timestamp': 1669852464, 'time_this_iter_s': 5.687568664550781, 'time_total_s': 5.687568664550781, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 5.687568664550781, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.21111111111111, 'ram_util_percent': 22.677777777777774}}\n",
      "Checkpoint saved to /home/codespace/ray_results/PPO_EPANETEnv_2022-11-30_23-54-074nspqvxo/checkpoint_000001\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 40.873109270135565, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.672142370285526, 'policy_loss': -0.01949855629605071, 'vf_loss': 9.691215599224131, 'vf_explained_var': -0.846986000896782, 'kl': 0.004253370983826175, 'entropy': 0.4551225243556884, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 8010, 'num_env_steps_trained': 8010, 'num_agent_steps_sampled': 8010, 'num_agent_steps_trained': 8010}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 8010, 'num_agent_steps_trained': 8010, 'num_env_steps_sampled': 8010, 'num_env_steps_trained': 8010, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 8010, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 8010, 'timers': {'training_iteration_time_ms': 5562.78, 'load_time_ms': 3.632, 'load_throughput': 1102713.593, 'learn_time_ms': 4349.872, 'learn_throughput': 920.717, 'synch_weights_time_ms': 3.3}, 'counters': {'num_env_steps_sampled': 8010, 'num_env_steps_trained': 8010, 'num_agent_steps_sampled': 8010, 'num_agent_steps_trained': 8010}, 'done': False, 'episodes_total': 0, 'training_iteration': 2, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-29', 'timestamp': 1669852469, 'time_this_iter_s': 5.448056697845459, 'time_total_s': 11.13562536239624, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 11.13562536239624, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.271428571428572, 'ram_util_percent': 22.714285714285715}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 869.1120237640356, 'cur_kl_coeff': 0.05000000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.251422814784512, 'policy_loss': 0.01841868132813483, 'vf_loss': 7.232804433184286, 'vf_explained_var': -0.094951545423077, 'kl': 0.00399401806944078, 'entropy': 0.2131488067468488, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 12015, 'num_env_steps_trained': 12015, 'num_agent_steps_sampled': 12015, 'num_agent_steps_trained': 12015}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 12015, 'num_agent_steps_trained': 12015, 'num_env_steps_sampled': 12015, 'num_env_steps_trained': 12015, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 12015, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 12015, 'timers': {'training_iteration_time_ms': 5600.636, 'load_time_ms': 4.888, 'load_throughput': 819383.812, 'learn_time_ms': 4364.435, 'learn_throughput': 917.645, 'synch_weights_time_ms': 3.429}, 'counters': {'num_env_steps_sampled': 12015, 'num_env_steps_trained': 12015, 'num_agent_steps_sampled': 12015, 'num_agent_steps_trained': 12015}, 'done': False, 'episodes_total': 0, 'training_iteration': 3, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-35', 'timestamp': 1669852475, 'time_this_iter_s': 5.6825292110443115, 'time_total_s': 16.81815457344055, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 16.81815457344055, 'timesteps_since_restore': 0, 'iterations_since_restore': 3, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.077777777777776, 'ram_util_percent': 22.71111111111111}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 42.82217559169737, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.635147974568028, 'policy_loss': -0.003381540824569041, 'vf_loss': 9.63811679040232, 'vf_explained_var': -1.0, 'kl': 0.016509310138269253, 'entropy': 0.5738138195487761, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 16020, 'num_env_steps_trained': 16020, 'num_agent_steps_sampled': 16020, 'num_agent_steps_trained': 16020}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 16020, 'num_agent_steps_trained': 16020, 'num_env_steps_sampled': 16020, 'num_env_steps_trained': 16020, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 16020, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 16020, 'timers': {'training_iteration_time_ms': 5545.922, 'load_time_ms': 5.753, 'load_throughput': 696211.353, 'learn_time_ms': 4339.532, 'learn_throughput': 922.911, 'synch_weights_time_ms': 3.327}, 'counters': {'num_env_steps_sampled': 16020, 'num_env_steps_trained': 16020, 'num_agent_steps_sampled': 16020, 'num_agent_steps_trained': 16020}, 'done': False, 'episodes_total': 0, 'training_iteration': 4, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-40', 'timestamp': 1669852480, 'time_this_iter_s': 5.386999130249023, 'time_total_s': 22.205153703689575, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 22.205153703689575, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.77142857142857, 'ram_util_percent': 22.785714285714285}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 552.8512110556005, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 6.684929512136726, 'policy_loss': -0.0007845309312625598, 'vf_loss': 6.685228816604101, 'vf_explained_var': -0.24567282577996613, 'kl': 0.01940789224344632, 'entropy': 0.6921123634102524, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 20025, 'num_env_steps_trained': 20025, 'num_agent_steps_sampled': 20025, 'num_agent_steps_trained': 20025}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 20025, 'num_agent_steps_trained': 20025, 'num_env_steps_sampled': 20025, 'num_env_steps_trained': 20025, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 20025, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 20025, 'timers': {'training_iteration_time_ms': 5556.362, 'load_time_ms': 6.347, 'load_throughput': 631045.828, 'learn_time_ms': 4353.503, 'learn_throughput': 919.949, 'synch_weights_time_ms': 3.466}, 'counters': {'num_env_steps_sampled': 20025, 'num_env_steps_trained': 20025, 'num_agent_steps_sampled': 20025, 'num_agent_steps_trained': 20025}, 'done': False, 'episodes_total': 0, 'training_iteration': 5, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-46', 'timestamp': 1669852486, 'time_this_iter_s': 5.602875232696533, 'time_total_s': 27.80802893638611, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 27.80802893638611, 'timesteps_since_restore': 0, 'iterations_since_restore': 5, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.4375, 'ram_util_percent': 22.8}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 34.8583774336083, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.830396105653497, 'policy_loss': 0.021786252486329247, 'vf_loss': 9.808183757207727, 'vf_explained_var': 0.02127821849238488, 'kl': 0.0170444588047617, 'entropy': 0.6676550934391637, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 24030, 'num_env_steps_trained': 24030, 'num_agent_steps_sampled': 24030, 'num_agent_steps_trained': 24030}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 24030, 'num_agent_steps_trained': 24030, 'num_env_steps_sampled': 24030, 'num_env_steps_trained': 24030, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 24030, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 24030, 'timers': {'training_iteration_time_ms': 5543.798, 'load_time_ms': 6.406, 'load_throughput': 625169.025, 'learn_time_ms': 4364.874, 'learn_throughput': 917.552, 'synch_weights_time_ms': 3.408}, 'counters': {'num_env_steps_sampled': 24030, 'num_env_steps_trained': 24030, 'num_agent_steps_sampled': 24030, 'num_agent_steps_trained': 24030}, 'done': False, 'episodes_total': 0, 'training_iteration': 6, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-52', 'timestamp': 1669852492, 'time_this_iter_s': 5.486346960067749, 'time_total_s': 33.29437589645386, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 33.29437589645386, 'timesteps_since_restore': 0, 'iterations_since_restore': 6, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.625, 'ram_util_percent': 22.8125}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 32.97650760004738, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.931092988291095, 'policy_loss': 0.0007898153036191899, 'vf_loss': 9.92981796674831, 'vf_explained_var': -0.7638726519641056, 'kl': 0.019407596781946878, 'entropy': 0.6858426229287219, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 28035, 'num_env_steps_trained': 28035, 'num_agent_steps_sampled': 28035, 'num_agent_steps_trained': 28035}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 28035, 'num_agent_steps_trained': 28035, 'num_env_steps_sampled': 28035, 'num_env_steps_trained': 28035, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 28035, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 28035, 'timers': {'training_iteration_time_ms': 5556.2, 'load_time_ms': 6.975, 'load_throughput': 574193.248, 'learn_time_ms': 4366.999, 'learn_throughput': 917.106, 'synch_weights_time_ms': 3.359}, 'counters': {'num_env_steps_sampled': 28035, 'num_env_steps_trained': 28035, 'num_agent_steps_sampled': 28035, 'num_agent_steps_trained': 28035}, 'done': False, 'episodes_total': 9, 'training_iteration': 7, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-54-57', 'timestamp': 1669852497, 'time_this_iter_s': 5.635837078094482, 'time_total_s': 38.93021297454834, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 38.93021297454834, 'timesteps_since_restore': 0, 'iterations_since_restore': 7, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.775, 'ram_util_percent': 22.9}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.240925132218868, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.752454438773535, 'policy_loss': -0.018925864512341156, 'vf_loss': 9.771088764231692, 'vf_explained_var': -0.955093886262627, 'kl': 0.0116624053371709, 'entropy': 0.6818809932278048, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 32040, 'num_env_steps_trained': 32040, 'num_agent_steps_sampled': 32040, 'num_agent_steps_trained': 32040}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 32040, 'num_agent_steps_trained': 32040, 'num_env_steps_sampled': 32040, 'num_env_steps_trained': 32040, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 32040, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 32040, 'timers': {'training_iteration_time_ms': 5555.683, 'load_time_ms': 7.369, 'load_throughput': 543470.173, 'learn_time_ms': 4378.289, 'learn_throughput': 914.741, 'synch_weights_time_ms': 3.325}, 'counters': {'num_env_steps_sampled': 32040, 'num_env_steps_trained': 32040, 'num_agent_steps_sampled': 32040, 'num_agent_steps_trained': 32040}, 'done': False, 'episodes_total': 9, 'training_iteration': 8, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-03', 'timestamp': 1669852503, 'time_this_iter_s': 5.557160377502441, 'time_total_s': 44.48737335205078, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 44.48737335205078, 'timesteps_since_restore': 0, 'iterations_since_restore': 8, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.1625, 'ram_util_percent': 23.0}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 554.4019344219597, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.405841566798507, 'policy_loss': -0.018141501062419466, 'vf_loss': 8.42369030021852, 'vf_explained_var': -0.85988942583402, 'kl': 0.01171115382239267, 'entropy': 0.5900990240035519, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 36045, 'num_env_steps_trained': 36045, 'num_agent_steps_sampled': 36045, 'num_agent_steps_trained': 36045}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 36045, 'num_agent_steps_trained': 36045, 'num_env_steps_sampled': 36045, 'num_env_steps_trained': 36045, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 36045, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 36045, 'timers': {'training_iteration_time_ms': 5570.099, 'load_time_ms': 7.45, 'load_throughput': 537601.256, 'learn_time_ms': 4387.529, 'learn_throughput': 912.814, 'synch_weights_time_ms': 3.309}, 'counters': {'num_env_steps_sampled': 36045, 'num_env_steps_trained': 36045, 'num_agent_steps_sampled': 36045, 'num_agent_steps_trained': 36045}, 'done': False, 'episodes_total': 9, 'training_iteration': 9, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-09', 'timestamp': 1669852509, 'time_this_iter_s': 5.690060615539551, 'time_total_s': 50.17743396759033, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 50.17743396759033, 'timesteps_since_restore': 0, 'iterations_since_restore': 9, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.6, 'ram_util_percent': 23.05}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 25.454006337342403, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.915828916077972, 'policy_loss': 0.002609280456778824, 'vf_loss': 9.911990314401606, 'vf_explained_var': -0.7606811408073672, 'kl': 0.04917203220361517, 'entropy': 0.6397381159567064, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 40050, 'num_env_steps_trained': 40050, 'num_agent_steps_sampled': 40050, 'num_agent_steps_trained': 40050}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 40050, 'num_agent_steps_trained': 40050, 'num_env_steps_sampled': 40050, 'num_env_steps_trained': 40050, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 40050, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 40050, 'timers': {'training_iteration_time_ms': 5560.719, 'load_time_ms': 7.468, 'load_throughput': 536294.365, 'learn_time_ms': 4389.3, 'learn_throughput': 912.446, 'synch_weights_time_ms': 3.274}, 'counters': {'num_env_steps_sampled': 40050, 'num_env_steps_trained': 40050, 'num_agent_steps_sampled': 40050, 'num_agent_steps_trained': 40050}, 'done': False, 'episodes_total': 9, 'training_iteration': 10, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-14', 'timestamp': 1669852514, 'time_this_iter_s': 5.48309850692749, 'time_total_s': 55.66053247451782, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 55.66053247451782, 'timesteps_since_restore': 0, 'iterations_since_restore': 10, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.175, 'ram_util_percent': 23.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 141.4416510846506, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.095500694295412, 'policy_loss': -0.015328458914413087, 'vf_loss': 9.110571301880704, 'vf_explained_var': -1.0, 'kl': 0.006875927493165526, 'entropy': 0.6909511519375667, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 44055, 'num_env_steps_trained': 44055, 'num_agent_steps_sampled': 44055, 'num_agent_steps_trained': 44055}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 44055, 'num_agent_steps_trained': 44055, 'num_env_steps_sampled': 44055, 'num_env_steps_trained': 44055, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 44055, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 44055, 'timers': {'training_iteration_time_ms': 5554.527, 'load_time_ms': 8.488, 'load_throughput': 471863.176, 'learn_time_ms': 4399.69, 'learn_throughput': 910.291, 'synch_weights_time_ms': 3.291}, 'counters': {'num_env_steps_sampled': 44055, 'num_env_steps_trained': 44055, 'num_agent_steps_sampled': 44055, 'num_agent_steps_trained': 44055}, 'done': False, 'episodes_total': 9, 'training_iteration': 11, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-20', 'timestamp': 1669852520, 'time_this_iter_s': 5.626384735107422, 'time_total_s': 61.286917209625244, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 61.286917209625244, 'timesteps_since_restore': 0, 'iterations_since_restore': 11, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.025, 'ram_util_percent': 23.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 544.9837818925739, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.928132849867626, 'policy_loss': 0.009445558957034542, 'vf_loss': 7.918082528985956, 'vf_explained_var': -0.11437664852347425, 'kl': 0.01612807762424763, 'entropy': 0.6427047364814307, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 48060, 'num_env_steps_trained': 48060, 'num_agent_steps_sampled': 48060, 'num_agent_steps_trained': 48060}, 'sampler_results': {'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1282.0456116724918, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1259.1188150837288, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42551379284731516, 'mean_inference_ms': 1.1898864184444735, 'mean_action_processing_ms': 0.06973359166870204, 'mean_env_wait_ms': 0.32640585731361615, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 48060, 'num_agent_steps_trained': 48060, 'num_env_steps_sampled': 48060, 'num_env_steps_trained': 48060, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 48060, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 48060, 'timers': {'training_iteration_time_ms': 5577.06, 'load_time_ms': 8.952, 'load_throughput': 447379.022, 'learn_time_ms': 4416.667, 'learn_throughput': 906.792, 'synch_weights_time_ms': 3.221}, 'counters': {'num_env_steps_sampled': 48060, 'num_env_steps_trained': 48060, 'num_agent_steps_sampled': 48060, 'num_agent_steps_trained': 48060}, 'done': False, 'episodes_total': 9, 'training_iteration': 12, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-25', 'timestamp': 1669852525, 'time_this_iter_s': 5.676667928695679, 'time_total_s': 66.96358513832092, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 66.96358513832092, 'timesteps_since_restore': 0, 'iterations_since_restore': 12, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.8625, 'ram_util_percent': 23.1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.53580528947735, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.584569102974347, 'policy_loss': 0.01758688750967223, 'vf_loss': 9.566815918748096, 'vf_explained_var': -1.0, 'kl': 0.004435356485537661, 'entropy': 0.5398236116414429, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 52065, 'num_env_steps_trained': 52065, 'num_agent_steps_sampled': 52065, 'num_agent_steps_trained': 52065}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 52065, 'num_agent_steps_trained': 52065, 'num_env_steps_sampled': 52065, 'num_env_steps_trained': 52065, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 52065, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 52065, 'timers': {'training_iteration_time_ms': 5576.136, 'load_time_ms': 9.547, 'load_throughput': 419521.532, 'learn_time_ms': 4430.332, 'learn_throughput': 903.995, 'synch_weights_time_ms': 3.157}, 'counters': {'num_env_steps_sampled': 52065, 'num_env_steps_trained': 52065, 'num_agent_steps_sampled': 52065, 'num_agent_steps_trained': 52065}, 'done': False, 'episodes_total': 18, 'training_iteration': 13, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-31', 'timestamp': 1669852531, 'time_this_iter_s': 5.673491477966309, 'time_total_s': 72.63707661628723, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 72.63707661628723, 'timesteps_since_restore': 0, 'iterations_since_restore': 13, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.2875, 'ram_util_percent': 23.1875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.585645951975578, 'cur_kl_coeff': 0.01875, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.77217696200135, 'policy_loss': -0.020949727211708343, 'vf_loss': 9.79303795701714, 'vf_explained_var': -0.005421060900534353, 'kl': 0.004734096040706932, 'entropy': 0.6555925914677241, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 56070, 'num_env_steps_trained': 56070, 'num_agent_steps_sampled': 56070, 'num_agent_steps_trained': 56070}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 56070, 'num_agent_steps_trained': 56070, 'num_env_steps_sampled': 56070, 'num_env_steps_trained': 56070, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 56070, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 56070, 'timers': {'training_iteration_time_ms': 5596.563, 'load_time_ms': 9.98, 'load_throughput': 401317.503, 'learn_time_ms': 4457.692, 'learn_throughput': 898.447, 'synch_weights_time_ms': 3.145}, 'counters': {'num_env_steps_sampled': 56070, 'num_env_steps_trained': 56070, 'num_agent_steps_sampled': 56070, 'num_agent_steps_trained': 56070}, 'done': False, 'episodes_total': 18, 'training_iteration': 14, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-37', 'timestamp': 1669852537, 'time_this_iter_s': 5.590928554534912, 'time_total_s': 78.22800517082214, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 78.22800517082214, 'timesteps_since_restore': 0, 'iterations_since_restore': 14, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.299999999999997, 'ram_util_percent': 23.2125}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 183.44684694556778, 'cur_kl_coeff': 0.009375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.82418202982154, 'policy_loss': 0.017263497565422326, 'vf_loss': 8.806885571377252, 'vf_explained_var': 0.08167342152646793, 'kl': 0.00351757040068848, 'entropy': 0.5326083177199927, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 60075, 'num_env_steps_trained': 60075, 'num_agent_steps_sampled': 60075, 'num_agent_steps_trained': 60075}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 60075, 'num_agent_steps_trained': 60075, 'num_env_steps_sampled': 60075, 'num_env_steps_trained': 60075, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 60075, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 60075, 'timers': {'training_iteration_time_ms': 5611.493, 'load_time_ms': 10.084, 'load_throughput': 397177.549, 'learn_time_ms': 4479.389, 'learn_throughput': 894.095, 'synch_weights_time_ms': 3.038}, 'counters': {'num_env_steps_sampled': 60075, 'num_env_steps_trained': 60075, 'num_agent_steps_sampled': 60075, 'num_agent_steps_trained': 60075}, 'done': False, 'episodes_total': 18, 'training_iteration': 15, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-42', 'timestamp': 1669852542, 'time_this_iter_s': 5.7535364627838135, 'time_total_s': 83.98154163360596, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 83.98154163360596, 'timesteps_since_restore': 0, 'iterations_since_restore': 15, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.51111111111111, 'ram_util_percent': 23.22222222222222}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1514.6948784277645, 'cur_kl_coeff': 0.0046875, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 4.513970478984618, 'policy_loss': 0.02428351097930503, 'vf_loss': 4.489649059244942, 'vf_explained_var': 0.21722008124474557, 'kl': 0.008089983803991748, 'entropy': 0.4394272359789059, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 64080, 'num_env_steps_trained': 64080, 'num_agent_steps_sampled': 64080, 'num_agent_steps_trained': 64080}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 64080, 'num_agent_steps_trained': 64080, 'num_env_steps_sampled': 64080, 'num_env_steps_trained': 64080, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 64080, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 64080, 'timers': {'training_iteration_time_ms': 5624.054, 'load_time_ms': 10.229, 'load_throughput': 391516.861, 'learn_time_ms': 4488.859, 'learn_throughput': 892.209, 'synch_weights_time_ms': 3.074}, 'counters': {'num_env_steps_sampled': 64080, 'num_env_steps_trained': 64080, 'num_agent_steps_sampled': 64080, 'num_agent_steps_trained': 64080}, 'done': False, 'episodes_total': 18, 'training_iteration': 16, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-48', 'timestamp': 1669852548, 'time_this_iter_s': 5.612451076507568, 'time_total_s': 89.59399271011353, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 89.59399271011353, 'timesteps_since_restore': 0, 'iterations_since_restore': 16, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.9375, 'ram_util_percent': 23.2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 497.7757659972355, 'cur_kl_coeff': 0.0046875, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 4.691687747419522, 'policy_loss': -0.0015294556255622577, 'vf_loss': 4.693157155515365, 'vf_explained_var': -0.2425563955819735, 'kl': 0.012809480205634785, 'entropy': 0.6710728601742816, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 68085, 'num_env_steps_trained': 68085, 'num_agent_steps_sampled': 68085, 'num_agent_steps_trained': 68085}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 68085, 'num_agent_steps_trained': 68085, 'num_env_steps_sampled': 68085, 'num_env_steps_trained': 68085, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 68085, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 68085, 'timers': {'training_iteration_time_ms': 5632.994, 'load_time_ms': 10.414, 'load_throughput': 384565.966, 'learn_time_ms': 4511.67, 'learn_throughput': 887.698, 'synch_weights_time_ms': 3.046}, 'counters': {'num_env_steps_sampled': 68085, 'num_env_steps_trained': 68085, 'num_agent_steps_sampled': 68085, 'num_agent_steps_trained': 68085}, 'done': False, 'episodes_total': 18, 'training_iteration': 17, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-55-54', 'timestamp': 1669852554, 'time_this_iter_s': 5.726475715637207, 'time_total_s': 95.32046842575073, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 95.32046842575073, 'timesteps_since_restore': 0, 'iterations_since_restore': 17, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.0, 'ram_util_percent': 23.25}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 480.17050681966606, 'cur_kl_coeff': 0.0046875, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 4.241452100200037, 'policy_loss': -0.009854569185965804, 'vf_loss': 4.251172417314143, 'vf_explained_var': 0.07883634868488516, 'kl': 0.02864116996653098, 'entropy': 0.6849417565971292, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 72090, 'num_env_steps_trained': 72090, 'num_agent_steps_sampled': 72090, 'num_agent_steps_trained': 72090}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 72090, 'num_agent_steps_trained': 72090, 'num_env_steps_sampled': 72090, 'num_env_steps_trained': 72090, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 72090, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 72090, 'timers': {'training_iteration_time_ms': 5648.325, 'load_time_ms': 10.361, 'load_throughput': 386556.23, 'learn_time_ms': 4523.737, 'learn_throughput': 885.33, 'synch_weights_time_ms': 3.082}, 'counters': {'num_env_steps_sampled': 72090, 'num_env_steps_trained': 72090, 'num_agent_steps_sampled': 72090, 'num_agent_steps_trained': 72090}, 'done': False, 'episodes_total': 18, 'training_iteration': 18, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-00', 'timestamp': 1669852560, 'time_this_iter_s': 5.710102796554565, 'time_total_s': 101.0305712223053, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 101.0305712223053, 'timesteps_since_restore': 0, 'iterations_since_restore': 18, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.2875, 'ram_util_percent': 23.25}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 448.94182743052, 'cur_kl_coeff': 0.007031250000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.16802079457243885, 'policy_loss': 0.018608653811006858, 'vf_loss': 0.14931513008108283, 'vf_explained_var': -0.050397789093755904, 'kl': 0.013797514979884493, 'entropy': 0.6712622949513056, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 76095, 'num_env_steps_trained': 76095, 'num_agent_steps_sampled': 76095, 'num_agent_steps_trained': 76095}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 1242.7674443211588, 'episode_reward_mean': 1334.3750467483949, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42402290089102335, 'mean_inference_ms': 1.1907471269424954, 'mean_action_processing_ms': 0.06942385744782927, 'mean_env_wait_ms': 0.3247240897405736, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 76095, 'num_agent_steps_trained': 76095, 'num_env_steps_sampled': 76095, 'num_env_steps_trained': 76095, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 76095, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 76095, 'timers': {'training_iteration_time_ms': 5655.871, 'load_time_ms': 10.422, 'load_throughput': 384294.116, 'learn_time_ms': 4538.316, 'learn_throughput': 882.486, 'synch_weights_time_ms': 3.068}, 'counters': {'num_env_steps_sampled': 76095, 'num_env_steps_trained': 76095, 'num_agent_steps_sampled': 76095, 'num_agent_steps_trained': 76095}, 'done': False, 'episodes_total': 18, 'training_iteration': 19, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-05', 'timestamp': 1669852565, 'time_this_iter_s': 5.766939163208008, 'time_total_s': 106.7975103855133, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 106.7975103855133, 'timesteps_since_restore': 0, 'iterations_since_restore': 19, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.6625, 'ram_util_percent': 23.3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 262.9515035003103, 'cur_kl_coeff': 0.007031250000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 5.786854188032048, 'policy_loss': -0.005888378423868969, 'vf_loss': 5.792599692025412, 'vf_explained_var': -0.1172908947031985, 'kl': 0.02031952444032621, 'entropy': 0.6885966573351173, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 80100, 'num_env_steps_trained': 80100, 'num_agent_steps_sampled': 80100, 'num_agent_steps_trained': 80100}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 80100, 'num_agent_steps_trained': 80100, 'num_env_steps_sampled': 80100, 'num_env_steps_trained': 80100, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 80100, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 80100, 'timers': {'training_iteration_time_ms': 5670.574, 'load_time_ms': 10.479, 'load_throughput': 382206.972, 'learn_time_ms': 4549.022, 'learn_throughput': 880.409, 'synch_weights_time_ms': 3.084}, 'counters': {'num_env_steps_sampled': 80100, 'num_env_steps_trained': 80100, 'num_agent_steps_sampled': 80100, 'num_agent_steps_trained': 80100}, 'done': False, 'episodes_total': 27, 'training_iteration': 20, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-11', 'timestamp': 1669852571, 'time_this_iter_s': 5.628528356552124, 'time_total_s': 112.42603874206543, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 112.42603874206543, 'timesteps_since_restore': 0, 'iterations_since_restore': 20, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.975, 'ram_util_percent': 23.325000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.67640199776218, 'cur_kl_coeff': 0.010546875000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.789052988893243, 'policy_loss': -0.017791893197003233, 'vf_loss': 9.806822611695976, 'vf_explained_var': -0.21976920257332505, 'kl': 0.002116880082294766, 'entropy': 0.6903484201559457, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 84105, 'num_env_steps_trained': 84105, 'num_agent_steps_sampled': 84105, 'num_agent_steps_trained': 84105}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 84105, 'num_agent_steps_trained': 84105, 'num_env_steps_sampled': 84105, 'num_env_steps_trained': 84105, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 84105, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 84105, 'timers': {'training_iteration_time_ms': 5663.999, 'load_time_ms': 10.235, 'load_throughput': 391303.449, 'learn_time_ms': 4554.247, 'learn_throughput': 879.399, 'synch_weights_time_ms': 3.088}, 'counters': {'num_env_steps_sampled': 84105, 'num_env_steps_trained': 84105, 'num_agent_steps_sampled': 84105, 'num_agent_steps_trained': 84105}, 'done': False, 'episodes_total': 27, 'training_iteration': 21, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-17', 'timestamp': 1669852577, 'time_this_iter_s': 5.560470342636108, 'time_total_s': 117.98650908470154, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 117.98650908470154, 'timesteps_since_restore': 0, 'iterations_since_restore': 21, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 23.6, 'ram_util_percent': 23.450000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.42087175354001, 'cur_kl_coeff': 0.005273437500000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.773435536251274, 'policy_loss': -0.024217072695553784, 'vf_loss': 9.797564927993282, 'vf_explained_var': -0.19340437618635034, 'kl': 0.016625855430799686, 'entropy': 0.6261990300429765, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 88110, 'num_env_steps_trained': 88110, 'num_agent_steps_sampled': 88110, 'num_agent_steps_trained': 88110}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 88110, 'num_agent_steps_trained': 88110, 'num_env_steps_sampled': 88110, 'num_env_steps_trained': 88110, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 88110, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 88110, 'timers': {'training_iteration_time_ms': 5669.569, 'load_time_ms': 10.299, 'load_throughput': 388854.134, 'learn_time_ms': 4555.094, 'learn_throughput': 879.235, 'synch_weights_time_ms': 3.089}, 'counters': {'num_env_steps_sampled': 88110, 'num_env_steps_trained': 88110, 'num_agent_steps_sampled': 88110, 'num_agent_steps_trained': 88110}, 'done': False, 'episodes_total': 27, 'training_iteration': 22, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-22', 'timestamp': 1669852582, 'time_this_iter_s': 5.730695486068726, 'time_total_s': 123.71720457077026, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 123.71720457077026, 'timesteps_since_restore': 0, 'iterations_since_restore': 22, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.15, 'ram_util_percent': 23.3875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 55.20849092792499, 'cur_kl_coeff': 0.005273437500000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.757578618396876, 'policy_loss': -0.026706756992886462, 'vf_loss': 9.784195992190352, 'vf_explained_var': -0.2756117038829352, 'kl': 0.016952561708628577, 'entropy': 0.5484019151938859, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 92115, 'num_env_steps_trained': 92115, 'num_agent_steps_sampled': 92115, 'num_agent_steps_trained': 92115}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 92115, 'num_agent_steps_trained': 92115, 'num_env_steps_sampled': 92115, 'num_env_steps_trained': 92115, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 92115, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 92115, 'timers': {'training_iteration_time_ms': 5714.53, 'load_time_ms': 10.202, 'load_throughput': 392584.667, 'learn_time_ms': 4584.008, 'learn_throughput': 873.69, 'synch_weights_time_ms': 3.118}, 'counters': {'num_env_steps_sampled': 92115, 'num_env_steps_trained': 92115, 'num_agent_steps_sampled': 92115, 'num_agent_steps_trained': 92115}, 'done': False, 'episodes_total': 27, 'training_iteration': 23, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-28', 'timestamp': 1669852588, 'time_this_iter_s': 6.122521877288818, 'time_total_s': 129.83972644805908, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 129.83972644805908, 'timesteps_since_restore': 0, 'iterations_since_restore': 23, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 36.45555555555555, 'ram_util_percent': 24.166666666666668}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 82.06651508023421, 'cur_kl_coeff': 0.005273437500000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.098556089401246, 'policy_loss': -0.019683335680434462, 'vf_loss': 9.118162244366061, 'vf_explained_var': -1.0, 'kl': 0.014639978325980962, 'entropy': 0.6268985447704151, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 96120, 'num_env_steps_trained': 96120, 'num_agent_steps_sampled': 96120, 'num_agent_steps_trained': 96120}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 96120, 'num_agent_steps_trained': 96120, 'num_env_steps_sampled': 96120, 'num_env_steps_trained': 96120, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 96120, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 96120, 'timers': {'training_iteration_time_ms': 5724.763, 'load_time_ms': 10.176, 'load_throughput': 393570.693, 'learn_time_ms': 4576.637, 'learn_throughput': 875.097, 'synch_weights_time_ms': 3.153}, 'counters': {'num_env_steps_sampled': 96120, 'num_env_steps_trained': 96120, 'num_agent_steps_sampled': 96120, 'num_agent_steps_trained': 96120}, 'done': False, 'episodes_total': 27, 'training_iteration': 24, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-34', 'timestamp': 1669852594, 'time_this_iter_s': 5.693171977996826, 'time_total_s': 135.5328984260559, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 135.5328984260559, 'timesteps_since_restore': 0, 'iterations_since_restore': 24, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.174999999999997, 'ram_util_percent': 24.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 774.0126621483685, 'cur_kl_coeff': 0.005273437500000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.461320206298623, 'policy_loss': 0.014928271200868391, 'vf_loss': 7.4463755458272916, 'vf_explained_var': -0.13694945176442463, 'kl': 0.0031079476209012395, 'entropy': 0.4980995085931593, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 100125, 'num_env_steps_trained': 100125, 'num_agent_steps_sampled': 100125, 'num_agent_steps_trained': 100125}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1021.3266836547518, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.424963354663857, 'mean_inference_ms': 1.1918423058412755, 'mean_action_processing_ms': 0.06925921812459078, 'mean_env_wait_ms': 0.32384744587571185, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 100125, 'num_agent_steps_trained': 100125, 'num_env_steps_sampled': 100125, 'num_env_steps_trained': 100125, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 100125, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 100125, 'timers': {'training_iteration_time_ms': 5721.75, 'load_time_ms': 10.079, 'load_throughput': 397362.635, 'learn_time_ms': 4574.865, 'learn_throughput': 875.436, 'synch_weights_time_ms': 3.158}, 'counters': {'num_env_steps_sampled': 100125, 'num_env_steps_trained': 100125, 'num_agent_steps_sampled': 100125, 'num_agent_steps_trained': 100125}, 'done': False, 'episodes_total': 27, 'training_iteration': 25, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-40', 'timestamp': 1669852600, 'time_this_iter_s': 5.7233052253723145, 'time_total_s': 141.25620365142822, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 141.25620365142822, 'timesteps_since_restore': 0, 'iterations_since_restore': 25, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.1875, 'ram_util_percent': 24.412499999999998}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.43706639931407, 'cur_kl_coeff': 0.0026367187500000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.29194249440265, 'policy_loss': 0.02129824624587131, 'vf_loss': 9.27063788239674, 'vf_explained_var': -0.9995341095873105, 'kl': 0.0024147954502988823, 'entropy': 0.3591919067566113, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 104130, 'num_env_steps_trained': 104130, 'num_agent_steps_sampled': 104130, 'num_agent_steps_trained': 104130}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 104130, 'num_agent_steps_trained': 104130, 'num_env_steps_sampled': 104130, 'num_env_steps_trained': 104130, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 104130, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 104130, 'timers': {'training_iteration_time_ms': 5721.115, 'load_time_ms': 10.484, 'load_throughput': 382016.618, 'learn_time_ms': 4558.094, 'learn_throughput': 878.657, 'synch_weights_time_ms': 3.161}, 'counters': {'num_env_steps_sampled': 104130, 'num_env_steps_trained': 104130, 'num_agent_steps_sampled': 104130, 'num_agent_steps_trained': 104130}, 'done': False, 'episodes_total': 36, 'training_iteration': 26, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-46', 'timestamp': 1669852606, 'time_this_iter_s': 5.605948448181152, 'time_total_s': 146.86215209960938, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 146.86215209960938, 'timesteps_since_restore': 0, 'iterations_since_restore': 26, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.662499999999998, 'ram_util_percent': 24.4375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.222155943532945, 'cur_kl_coeff': 0.0013183593750000003, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.808072986397692, 'policy_loss': -0.022699634310218597, 'vf_loss': 9.830752929564445, 'vf_explained_var': -0.5150274286987961, 'kl': 0.014970714024408523, 'entropy': 0.6879842871619809, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 108135, 'num_env_steps_trained': 108135, 'num_agent_steps_sampled': 108135, 'num_agent_steps_trained': 108135}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 108135, 'num_agent_steps_trained': 108135, 'num_env_steps_sampled': 108135, 'num_env_steps_trained': 108135, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 108135, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 108135, 'timers': {'training_iteration_time_ms': 5708.828, 'load_time_ms': 10.171, 'load_throughput': 393751.509, 'learn_time_ms': 4540.991, 'learn_throughput': 881.966, 'synch_weights_time_ms': 3.197}, 'counters': {'num_env_steps_sampled': 108135, 'num_env_steps_trained': 108135, 'num_agent_steps_sampled': 108135, 'num_agent_steps_trained': 108135}, 'done': False, 'episodes_total': 36, 'training_iteration': 27, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-51', 'timestamp': 1669852611, 'time_this_iter_s': 5.60454797744751, 'time_total_s': 152.46670007705688, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 152.46670007705688, 'timesteps_since_restore': 0, 'iterations_since_restore': 27, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.5125, 'ram_util_percent': 24.412499999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 55.35370874235066, 'cur_kl_coeff': 0.0013183593750000003, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.845686938685756, 'policy_loss': -0.011979372965632588, 'vf_loss': 9.857652731095591, 'vf_explained_var': -1.0, 'kl': 0.010296213767961148, 'entropy': 0.6741736739553431, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 112140, 'num_env_steps_trained': 112140, 'num_agent_steps_sampled': 112140, 'num_agent_steps_trained': 112140}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 112140, 'num_agent_steps_trained': 112140, 'num_env_steps_sampled': 112140, 'num_env_steps_trained': 112140, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 112140, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 112140, 'timers': {'training_iteration_time_ms': 5721.003, 'load_time_ms': 10.459, 'load_throughput': 382936.242, 'learn_time_ms': 4535.37, 'learn_throughput': 883.059, 'synch_weights_time_ms': 3.203}, 'counters': {'num_env_steps_sampled': 112140, 'num_env_steps_trained': 112140, 'num_agent_steps_sampled': 112140, 'num_agent_steps_trained': 112140}, 'done': False, 'episodes_total': 36, 'training_iteration': 28, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-56-57', 'timestamp': 1669852617, 'time_this_iter_s': 5.833351135253906, 'time_total_s': 158.3000512123108, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 158.3000512123108, 'timesteps_since_restore': 0, 'iterations_since_restore': 28, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.4625, 'ram_util_percent': 24.45}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 109.69960467898717, 'cur_kl_coeff': 0.0013183593750000003, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.732559524941188, 'policy_loss': 0.0068658602263738395, 'vf_loss': 9.725677383234425, 'vf_explained_var': -0.11076163829013866, 'kl': 0.012348802037048733, 'entropy': 0.6694749997508141, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 116145, 'num_env_steps_trained': 116145, 'num_agent_steps_sampled': 116145, 'num_agent_steps_trained': 116145}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 116145, 'num_agent_steps_trained': 116145, 'num_env_steps_sampled': 116145, 'num_env_steps_trained': 116145, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 116145, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 116145, 'timers': {'training_iteration_time_ms': 5703.483, 'load_time_ms': 10.446, 'load_throughput': 383382.84, 'learn_time_ms': 4522.725, 'learn_throughput': 885.528, 'synch_weights_time_ms': 3.227}, 'counters': {'num_env_steps_sampled': 116145, 'num_env_steps_trained': 116145, 'num_agent_steps_sampled': 116145, 'num_agent_steps_trained': 116145}, 'done': False, 'episodes_total': 36, 'training_iteration': 29, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-03', 'timestamp': 1669852623, 'time_this_iter_s': 5.59040093421936, 'time_total_s': 163.89045214653015, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 163.89045214653015, 'timesteps_since_restore': 0, 'iterations_since_restore': 29, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.05, 'ram_util_percent': 24.4625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.045017245548067, 'cur_kl_coeff': 0.0013183593750000003, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.764989965705462, 'policy_loss': -0.013047883952767538, 'vf_loss': 9.778029295193251, 'vf_explained_var': -0.9768789532364056, 'kl': 0.006504003628232416, 'entropy': 0.6886190565042598, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 120150, 'num_env_steps_trained': 120150, 'num_agent_steps_sampled': 120150, 'num_agent_steps_trained': 120150}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 120150, 'num_agent_steps_trained': 120150, 'num_env_steps_sampled': 120150, 'num_env_steps_trained': 120150, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 120150, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 120150, 'timers': {'training_iteration_time_ms': 5727.133, 'load_time_ms': 10.786, 'load_throughput': 371301.231, 'learn_time_ms': 4539.899, 'learn_throughput': 882.178, 'synch_weights_time_ms': 3.214}, 'counters': {'num_env_steps_sampled': 120150, 'num_env_steps_trained': 120150, 'num_agent_steps_sampled': 120150, 'num_agent_steps_trained': 120150}, 'done': False, 'episodes_total': 36, 'training_iteration': 30, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-09', 'timestamp': 1669852629, 'time_this_iter_s': 5.864843368530273, 'time_total_s': 169.75529551506042, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 169.75529551506042, 'timesteps_since_restore': 0, 'iterations_since_restore': 30, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.855555555555558, 'ram_util_percent': 24.433333333333334}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 701.9496192459137, 'cur_kl_coeff': 0.0013183593750000003, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.238804959866308, 'policy_loss': -0.00899597392167135, 'vf_loss': 7.247800222263542, 'vf_explained_var': -0.923761623969642, 'kl': 0.0005294409611771465, 'entropy': 0.6844113472328391, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 124155, 'num_env_steps_trained': 124155, 'num_agent_steps_sampled': 124155, 'num_agent_steps_trained': 124155}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 124155, 'num_agent_steps_trained': 124155, 'num_env_steps_sampled': 124155, 'num_env_steps_trained': 124155, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 124155, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 124155, 'timers': {'training_iteration_time_ms': 5728.096, 'load_time_ms': 10.755, 'load_throughput': 372377.009, 'learn_time_ms': 4531.351, 'learn_throughput': 883.842, 'synch_weights_time_ms': 3.199}, 'counters': {'num_env_steps_sampled': 124155, 'num_env_steps_trained': 124155, 'num_agent_steps_sampled': 124155, 'num_agent_steps_trained': 124155}, 'done': False, 'episodes_total': 36, 'training_iteration': 31, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-14', 'timestamp': 1669852634, 'time_this_iter_s': 5.569944858551025, 'time_total_s': 175.32524037361145, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 175.32524037361145, 'timesteps_since_restore': 0, 'iterations_since_restore': 31, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.912499999999998, 'ram_util_percent': 24.412499999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 459.21594420812465, 'cur_kl_coeff': 0.0006591796875000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.625487189539658, 'policy_loss': 0.020131206864951758, 'vf_loss': 8.605340606086356, 'vf_explained_var': 0.18820539353996193, 'kl': 0.023337800554882996, 'entropy': 0.6412435413688742, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 128160, 'num_env_steps_trained': 128160, 'num_agent_steps_sampled': 128160, 'num_agent_steps_trained': 128160}, 'sampler_results': {'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1451.9169684974831, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1100.2278371299476, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4260137143376572, 'mean_inference_ms': 1.1942308960405197, 'mean_action_processing_ms': 0.06932424749654163, 'mean_env_wait_ms': 0.3235798863049452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 128160, 'num_agent_steps_trained': 128160, 'num_env_steps_sampled': 128160, 'num_env_steps_trained': 128160, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 128160, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 128160, 'timers': {'training_iteration_time_ms': 5727.154, 'load_time_ms': 10.437, 'load_throughput': 383738.416, 'learn_time_ms': 4544.446, 'learn_throughput': 881.296, 'synch_weights_time_ms': 3.209}, 'counters': {'num_env_steps_sampled': 128160, 'num_env_steps_trained': 128160, 'num_agent_steps_sampled': 128160, 'num_agent_steps_trained': 128160}, 'done': False, 'episodes_total': 36, 'training_iteration': 32, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-20', 'timestamp': 1669852640, 'time_this_iter_s': 5.719549179077148, 'time_total_s': 181.0447895526886, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 181.0447895526886, 'timesteps_since_restore': 0, 'iterations_since_restore': 32, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.549999999999997, 'ram_util_percent': 24.325000000000003}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 12.748590060395578, 'cur_kl_coeff': 0.0009887695312499997, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.918041027233166, 'policy_loss': 0.001330803488931989, 'vf_loss': 9.91670871857674, 'vf_explained_var': -0.6187879008631553, 'kl': 0.001550213408877313, 'entropy': 0.636614655486999, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 132165, 'num_env_steps_trained': 132165, 'num_agent_steps_sampled': 132165, 'num_agent_steps_trained': 132165}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 132165, 'num_agent_steps_trained': 132165, 'num_env_steps_sampled': 132165, 'num_env_steps_trained': 132165, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 132165, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 132165, 'timers': {'training_iteration_time_ms': 5676.955, 'load_time_ms': 10.498, 'load_throughput': 381488.272, 'learn_time_ms': 4508.842, 'learn_throughput': 888.255, 'synch_weights_time_ms': 3.179}, 'counters': {'num_env_steps_sampled': 132165, 'num_env_steps_trained': 132165, 'num_agent_steps_sampled': 132165, 'num_agent_steps_trained': 132165}, 'done': False, 'episodes_total': 45, 'training_iteration': 33, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-25', 'timestamp': 1669852645, 'time_this_iter_s': 5.620684385299683, 'time_total_s': 186.66547393798828, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 186.66547393798828, 'timesteps_since_restore': 0, 'iterations_since_restore': 33, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.225, 'ram_util_percent': 24.4}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.268227169766861, 'cur_kl_coeff': 0.0004943847656249999, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.804908401735368, 'policy_loss': -0.025182095558572842, 'vf_loss': 9.830074685619723, 'vf_explained_var': -0.7588864220085965, 'kl': 0.031895984171449364, 'entropy': 0.6817979157611888, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 136170, 'num_env_steps_trained': 136170, 'num_agent_steps_sampled': 136170, 'num_agent_steps_trained': 136170}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 136170, 'num_agent_steps_trained': 136170, 'num_env_steps_sampled': 136170, 'num_env_steps_trained': 136170, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 136170, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 136170, 'timers': {'training_iteration_time_ms': 5688.483, 'load_time_ms': 10.485, 'load_throughput': 381972.316, 'learn_time_ms': 4529.887, 'learn_throughput': 884.128, 'synch_weights_time_ms': 3.15}, 'counters': {'num_env_steps_sampled': 136170, 'num_env_steps_trained': 136170, 'num_agent_steps_sampled': 136170, 'num_agent_steps_trained': 136170}, 'done': False, 'episodes_total': 45, 'training_iteration': 34, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-31', 'timestamp': 1669852651, 'time_this_iter_s': 5.809086561203003, 'time_total_s': 192.47456049919128, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 192.47456049919128, 'timesteps_since_restore': 0, 'iterations_since_restore': 34, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.975, 'ram_util_percent': 24.3125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 129.63410505406077, 'cur_kl_coeff': 0.0007415771484375002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.398304688033237, 'policy_loss': -0.017113013873978327, 'vf_loss': 9.415405269848403, 'vf_explained_var': -0.9810206882415279, 'kl': 0.016763410118766062, 'entropy': 0.6579010095006677, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 140175, 'num_env_steps_trained': 140175, 'num_agent_steps_sampled': 140175, 'num_agent_steps_trained': 140175}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 140175, 'num_agent_steps_trained': 140175, 'num_env_steps_sampled': 140175, 'num_env_steps_trained': 140175, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 140175, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 140175, 'timers': {'training_iteration_time_ms': 5673.552, 'load_time_ms': 10.436, 'load_throughput': 383781.375, 'learn_time_ms': 4523.142, 'learn_throughput': 885.446, 'synch_weights_time_ms': 3.143}, 'counters': {'num_env_steps_sampled': 140175, 'num_env_steps_trained': 140175, 'num_agent_steps_sampled': 140175, 'num_agent_steps_trained': 140175}, 'done': False, 'episodes_total': 45, 'training_iteration': 35, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-37', 'timestamp': 1669852657, 'time_this_iter_s': 5.575392723083496, 'time_total_s': 198.04995322227478, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 198.04995322227478, 'timesteps_since_restore': 0, 'iterations_since_restore': 35, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.125, 'ram_util_percent': 24.1}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.986808126139385, 'cur_kl_coeff': 0.0007415771484375002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.858343175662462, 'policy_loss': 0.005491387034936618, 'vf_loss': 9.852843408687141, 'vf_explained_var': -0.6563200414180755, 'kl': 0.011373198428428166, 'entropy': 0.6876419556397264, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 144180, 'num_env_steps_trained': 144180, 'num_agent_steps_sampled': 144180, 'num_agent_steps_trained': 144180}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 144180, 'num_agent_steps_trained': 144180, 'num_env_steps_sampled': 144180, 'num_env_steps_trained': 144180, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 144180, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 144180, 'timers': {'training_iteration_time_ms': 5676.095, 'load_time_ms': 10.099, 'load_throughput': 396581.184, 'learn_time_ms': 4540.454, 'learn_throughput': 882.07, 'synch_weights_time_ms': 3.131}, 'counters': {'num_env_steps_sampled': 144180, 'num_env_steps_trained': 144180, 'num_agent_steps_sampled': 144180, 'num_agent_steps_trained': 144180}, 'done': False, 'episodes_total': 45, 'training_iteration': 36, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-43', 'timestamp': 1669852663, 'time_this_iter_s': 5.631335973739624, 'time_total_s': 203.6812891960144, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 203.6812891960144, 'timesteps_since_restore': 0, 'iterations_since_restore': 36, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.8125, 'ram_util_percent': 24.1375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 69.42636003391718, 'cur_kl_coeff': 0.0007415771484375002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.363144820223573, 'policy_loss': -0.021055417968541063, 'vf_loss': 9.384182482381021, 'vf_explained_var': -1.0, 'kl': 0.02394699984496373, 'entropy': 0.6809429943561554, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 148185, 'num_env_steps_trained': 148185, 'num_agent_steps_sampled': 148185, 'num_agent_steps_trained': 148185}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 148185, 'num_agent_steps_trained': 148185, 'num_env_steps_sampled': 148185, 'num_env_steps_trained': 148185, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 148185, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 148185, 'timers': {'training_iteration_time_ms': 5686.696, 'load_time_ms': 10.065, 'load_throughput': 397928.359, 'learn_time_ms': 4541.388, 'learn_throughput': 881.889, 'synch_weights_time_ms': 3.133}, 'counters': {'num_env_steps_sampled': 148185, 'num_env_steps_trained': 148185, 'num_agent_steps_sampled': 148185, 'num_agent_steps_trained': 148185}, 'done': False, 'episodes_total': 45, 'training_iteration': 37, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-48', 'timestamp': 1669852668, 'time_this_iter_s': 5.708229303359985, 'time_total_s': 209.3895184993744, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 209.3895184993744, 'timesteps_since_restore': 0, 'iterations_since_restore': 37, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.03333333333333, 'ram_util_percent': 24.12222222222222}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 872.1676009157973, 'cur_kl_coeff': 0.0011123657226562497, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 6.791323847796328, 'policy_loss': 0.011872289514028897, 'vf_loss': 6.779431756081119, 'vf_explained_var': 0.01977990404252083, 'kl': 0.01780578926230142, 'entropy': 0.548720818886193, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 152190, 'num_env_steps_trained': 152190, 'num_agent_steps_sampled': 152190, 'num_agent_steps_trained': 152190}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1188.181008056453, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4270452560949275, 'mean_inference_ms': 1.195801369317277, 'mean_action_processing_ms': 0.06935901392196583, 'mean_env_wait_ms': 0.3234028984567186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 152190, 'num_agent_steps_trained': 152190, 'num_env_steps_sampled': 152190, 'num_env_steps_trained': 152190, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 152190, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 152190, 'timers': {'training_iteration_time_ms': 5654.239, 'load_time_ms': 10.144, 'load_throughput': 394812.996, 'learn_time_ms': 4530.8, 'learn_throughput': 883.95, 'synch_weights_time_ms': 3.079}, 'counters': {'num_env_steps_sampled': 152190, 'num_env_steps_trained': 152190, 'num_agent_steps_sampled': 152190, 'num_agent_steps_trained': 152190}, 'done': False, 'episodes_total': 45, 'training_iteration': 38, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-57-54', 'timestamp': 1669852674, 'time_this_iter_s': 5.507645606994629, 'time_total_s': 214.89716410636902, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 214.89716410636902, 'timesteps_since_restore': 0, 'iterations_since_restore': 38, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.028571428571432, 'ram_util_percent': 24.128571428571426}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.07172933371878, 'cur_kl_coeff': 0.0011123657226562497, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.102525592106645, 'policy_loss': 0.016081233014182378, 'vf_loss': 9.086438432816536, 'vf_explained_var': -0.9505840870641893, 'kl': 0.0053028266110057365, 'entropy': 0.5274988500020837, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 156195, 'num_env_steps_trained': 156195, 'num_agent_steps_sampled': 156195, 'num_agent_steps_trained': 156195}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 156195, 'num_agent_steps_trained': 156195, 'num_env_steps_sampled': 156195, 'num_env_steps_trained': 156195, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 156195, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 156195, 'timers': {'training_iteration_time_ms': 5673.188, 'load_time_ms': 10.528, 'load_throughput': 380402.353, 'learn_time_ms': 4531.694, 'learn_throughput': 883.776, 'synch_weights_time_ms': 3.1}, 'counters': {'num_env_steps_sampled': 156195, 'num_env_steps_trained': 156195, 'num_agent_steps_sampled': 156195, 'num_agent_steps_trained': 156195}, 'done': False, 'episodes_total': 54, 'training_iteration': 39, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-00', 'timestamp': 1669852680, 'time_this_iter_s': 5.780802249908447, 'time_total_s': 220.67796635627747, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 220.67796635627747, 'timesteps_since_restore': 0, 'iterations_since_restore': 39, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.133333333333336, 'ram_util_percent': 24.188888888888886}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.627107911613039, 'cur_kl_coeff': 0.0011123657226562497, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.797560196538125, 'policy_loss': -0.02484771006850786, 'vf_loss': 9.822387996796639, 'vf_explained_var': -0.5299239304116977, 'kl': 0.01791103076517116, 'entropy': 0.6885954595381214, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 160200, 'num_env_steps_trained': 160200, 'num_agent_steps_sampled': 160200, 'num_agent_steps_trained': 160200}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 160200, 'num_agent_steps_trained': 160200, 'num_env_steps_sampled': 160200, 'num_env_steps_trained': 160200, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 160200, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 160200, 'timers': {'training_iteration_time_ms': 5644.397, 'load_time_ms': 10.644, 'load_throughput': 376253.755, 'learn_time_ms': 4508.124, 'learn_throughput': 888.396, 'synch_weights_time_ms': 3.121}, 'counters': {'num_env_steps_sampled': 160200, 'num_env_steps_trained': 160200, 'num_agent_steps_sampled': 160200, 'num_agent_steps_trained': 160200}, 'done': False, 'episodes_total': 54, 'training_iteration': 40, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-05', 'timestamp': 1669852685, 'time_this_iter_s': 5.57956337928772, 'time_total_s': 226.25752973556519, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 226.25752973556519, 'timesteps_since_restore': 0, 'iterations_since_restore': 40, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.462500000000002, 'ram_util_percent': 24.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 319.8899131154161, 'cur_kl_coeff': 0.0011123657226562497, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.774665488735321, 'policy_loss': -0.013218627870082855, 'vf_loss': 8.787851614593178, 'vf_explained_var': -0.9103725616009005, 'kl': 0.029206327716523296, 'entropy': 0.6815862408889237, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 164205, 'num_env_steps_trained': 164205, 'num_agent_steps_sampled': 164205, 'num_agent_steps_trained': 164205}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 164205, 'num_agent_steps_trained': 164205, 'num_env_steps_sampled': 164205, 'num_env_steps_trained': 164205, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 164205, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 164205, 'timers': {'training_iteration_time_ms': 5665.075, 'load_time_ms': 10.748, 'load_throughput': 372632.255, 'learn_time_ms': 4512.783, 'learn_throughput': 887.479, 'synch_weights_time_ms': 3.142}, 'counters': {'num_env_steps_sampled': 164205, 'num_env_steps_trained': 164205, 'num_agent_steps_sampled': 164205, 'num_agent_steps_trained': 164205}, 'done': False, 'episodes_total': 54, 'training_iteration': 41, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-11', 'timestamp': 1669852691, 'time_this_iter_s': 5.776837587356567, 'time_total_s': 232.03436732292175, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 232.03436732292175, 'timesteps_since_restore': 0, 'iterations_since_restore': 41, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.825, 'ram_util_percent': 24.2125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 555.5449905880797, 'cur_kl_coeff': 0.0016685485839843745, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.60003909620867, 'policy_loss': 0.013821873414300141, 'vf_loss': 8.58619865819972, 'vf_explained_var': -0.11434579299342247, 'kl': 0.011113812782267498, 'entropy': 0.5885661687902225, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 168210, 'num_env_steps_trained': 168210, 'num_agent_steps_sampled': 168210, 'num_agent_steps_trained': 168210}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 168210, 'num_agent_steps_trained': 168210, 'num_env_steps_sampled': 168210, 'num_env_steps_trained': 168210, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 168210, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 168210, 'timers': {'training_iteration_time_ms': 5647.915, 'load_time_ms': 11.159, 'load_throughput': 358898.054, 'learn_time_ms': 4490.699, 'learn_throughput': 891.843, 'synch_weights_time_ms': 3.106}, 'counters': {'num_env_steps_sampled': 168210, 'num_env_steps_trained': 168210, 'num_agent_steps_sampled': 168210, 'num_agent_steps_trained': 168210}, 'done': False, 'episodes_total': 54, 'training_iteration': 42, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-17', 'timestamp': 1669852697, 'time_this_iter_s': 5.548821210861206, 'time_total_s': 237.58318853378296, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 237.58318853378296, 'timesteps_since_restore': 0, 'iterations_since_restore': 42, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.0875, 'ram_util_percent': 24.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.271809806206054, 'cur_kl_coeff': 0.0016685485839843745, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.786322719820085, 'policy_loss': -0.016177279618318365, 'vf_loss': 9.802497906838694, 'vf_explained_var': -0.9924838392965255, 'kl': 0.0012837602402697833, 'entropy': 0.6614912590672893, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 172215, 'num_env_steps_trained': 172215, 'num_agent_steps_sampled': 172215, 'num_agent_steps_trained': 172215}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 172215, 'num_agent_steps_trained': 172215, 'num_env_steps_sampled': 172215, 'num_env_steps_trained': 172215, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 172215, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 172215, 'timers': {'training_iteration_time_ms': 5651.73, 'load_time_ms': 10.73, 'load_throughput': 373264.854, 'learn_time_ms': 4486.706, 'learn_throughput': 892.637, 'synch_weights_time_ms': 3.117}, 'counters': {'num_env_steps_sampled': 172215, 'num_env_steps_trained': 172215, 'num_agent_steps_sampled': 172215, 'num_agent_steps_trained': 172215}, 'done': False, 'episodes_total': 54, 'training_iteration': 43, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-22', 'timestamp': 1669852702, 'time_this_iter_s': 5.6581034660339355, 'time_total_s': 243.2412919998169, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 243.2412919998169, 'timesteps_since_restore': 0, 'iterations_since_restore': 43, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.45, 'ram_util_percent': 24.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 986.5978435495527, 'cur_kl_coeff': 0.0008342742919921872, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 6.637713446540217, 'policy_loss': -0.01793042626832762, 'vf_loss': 6.655611316427108, 'vf_explained_var': -0.8195433610229081, 'kl': 0.039009488674705266, 'entropy': 0.6913990011779211, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 176220, 'num_env_steps_trained': 176220, 'num_agent_steps_sampled': 176220, 'num_agent_steps_trained': 176220}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 176220, 'num_agent_steps_trained': 176220, 'num_env_steps_sampled': 176220, 'num_env_steps_trained': 176220, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 176220, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 176220, 'timers': {'training_iteration_time_ms': 5618.175, 'load_time_ms': 10.382, 'load_throughput': 385769.706, 'learn_time_ms': 4459.563, 'learn_throughput': 898.07, 'synch_weights_time_ms': 3.112}, 'counters': {'num_env_steps_sampled': 176220, 'num_env_steps_trained': 176220, 'num_agent_steps_sampled': 176220, 'num_agent_steps_trained': 176220}, 'done': False, 'episodes_total': 54, 'training_iteration': 44, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-28', 'timestamp': 1669852708, 'time_this_iter_s': 5.4740681648254395, 'time_total_s': 248.71536016464233, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 248.71536016464233, 'timesteps_since_restore': 0, 'iterations_since_restore': 44, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.4625, 'ram_util_percent': 24.35}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 18.46769864892447, 'cur_kl_coeff': 0.0012514114379882813, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.784067216483496, 'policy_loss': 0.020493776295133815, 'vf_loss': 9.76355929323422, 'vf_explained_var': -0.170585008077724, 'kl': 0.011310827558897304, 'entropy': 0.6878229406572157, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 180225, 'num_env_steps_trained': 180225, 'num_agent_steps_sampled': 180225, 'num_agent_steps_trained': 180225}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1226.5954953588691, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4273455266378288, 'mean_inference_ms': 1.1961907710435535, 'mean_action_processing_ms': 0.06933051753224692, 'mean_env_wait_ms': 0.32305006508292256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 180225, 'num_agent_steps_trained': 180225, 'num_env_steps_sampled': 180225, 'num_env_steps_trained': 180225, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 180225, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 180225, 'timers': {'training_iteration_time_ms': 5639.662, 'load_time_ms': 10.462, 'load_throughput': 382798.365, 'learn_time_ms': 4464.025, 'learn_throughput': 897.172, 'synch_weights_time_ms': 3.121}, 'counters': {'num_env_steps_sampled': 180225, 'num_env_steps_trained': 180225, 'num_agent_steps_sampled': 180225, 'num_agent_steps_trained': 180225}, 'done': False, 'episodes_total': 54, 'training_iteration': 45, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-34', 'timestamp': 1669852714, 'time_this_iter_s': 5.788562297821045, 'time_total_s': 254.50392246246338, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 254.50392246246338, 'timesteps_since_restore': 0, 'iterations_since_restore': 45, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.6375, 'ram_util_percent': 24.3625}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.737663123428181, 'cur_kl_coeff': 0.0012514114379882813, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.912314844644198, 'policy_loss': -0.0031264026318826984, 'vf_loss': 9.91543058272331, 'vf_explained_var': -0.5683687413892439, 'kl': 0.00853501564300233, 'entropy': 0.6750494214796251, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 184230, 'num_env_steps_trained': 184230, 'num_agent_steps_sampled': 184230, 'num_agent_steps_trained': 184230}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 184230, 'num_agent_steps_trained': 184230, 'num_env_steps_sampled': 184230, 'num_env_steps_trained': 184230, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 184230, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 184230, 'timers': {'training_iteration_time_ms': 5637.315, 'load_time_ms': 10.805, 'load_throughput': 370666.268, 'learn_time_ms': 4457.805, 'learn_throughput': 898.424, 'synch_weights_time_ms': 3.091}, 'counters': {'num_env_steps_sampled': 184230, 'num_env_steps_trained': 184230, 'num_agent_steps_sampled': 184230, 'num_agent_steps_trained': 184230}, 'done': False, 'episodes_total': 63, 'training_iteration': 46, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-39', 'timestamp': 1669852719, 'time_this_iter_s': 5.607389450073242, 'time_total_s': 260.1113119125366, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 260.1113119125366, 'timesteps_since_restore': 0, 'iterations_since_restore': 46, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.3875, 'ram_util_percent': 24.375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 253.26686002701842, 'cur_kl_coeff': 0.0012514114379882813, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.0176290540285, 'policy_loss': -0.01584470646996652, 'vf_loss': 9.033439584444928, 'vf_explained_var': -0.7632282495498657, 'kl': 0.027295993423131725, 'entropy': 0.6895661122055464, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 188235, 'num_env_steps_trained': 188235, 'num_agent_steps_sampled': 188235, 'num_agent_steps_trained': 188235}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 188235, 'num_agent_steps_trained': 188235, 'num_env_steps_sampled': 188235, 'num_env_steps_trained': 188235, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 188235, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 188235, 'timers': {'training_iteration_time_ms': 5638.616, 'load_time_ms': 11.199, 'load_throughput': 357634.24, 'learn_time_ms': 4476.364, 'learn_throughput': 894.699, 'synch_weights_time_ms': 3.062}, 'counters': {'num_env_steps_sampled': 188235, 'num_env_steps_trained': 188235, 'num_agent_steps_sampled': 188235, 'num_agent_steps_trained': 188235}, 'done': False, 'episodes_total': 63, 'training_iteration': 47, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-45', 'timestamp': 1669852725, 'time_this_iter_s': 5.721083164215088, 'time_total_s': 265.8323950767517, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 265.8323950767517, 'timesteps_since_restore': 0, 'iterations_since_restore': 47, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.662499999999998, 'ram_util_percent': 24.45}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 206.6440749771704, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.418951664208084, 'policy_loss': 0.015389879630698312, 'vf_loss': 9.403530914040022, 'vf_explained_var': 0.3339777797781011, 'kl': 0.016437626756344005, 'entropy': 0.6764959994182792, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 192240, 'num_env_steps_trained': 192240, 'num_agent_steps_sampled': 192240, 'num_agent_steps_trained': 192240}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 192240, 'num_agent_steps_trained': 192240, 'num_env_steps_sampled': 192240, 'num_env_steps_trained': 192240, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 192240, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 192240, 'timers': {'training_iteration_time_ms': 5644.892, 'load_time_ms': 10.744, 'load_throughput': 372769.522, 'learn_time_ms': 4478.191, 'learn_throughput': 894.334, 'synch_weights_time_ms': 3.079}, 'counters': {'num_env_steps_sampled': 192240, 'num_env_steps_trained': 192240, 'num_agent_steps_sampled': 192240, 'num_agent_steps_trained': 192240}, 'done': False, 'episodes_total': 63, 'training_iteration': 48, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-51', 'timestamp': 1669852731, 'time_this_iter_s': 5.570789575576782, 'time_total_s': 271.4031846523285, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 271.4031846523285, 'timesteps_since_restore': 0, 'iterations_since_restore': 48, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.299999999999997, 'ram_util_percent': 24.2875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 147.7973206454908, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.408635413262152, 'policy_loss': 0.0010078879133347542, 'vf_loss': 9.40760608642332, 'vf_explained_var': -0.5746180841358759, 'kl': 0.011422160796268226, 'entropy': 0.6682721478323783, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 196245, 'num_env_steps_trained': 196245, 'num_agent_steps_sampled': 196245, 'num_agent_steps_trained': 196245}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 196245, 'num_agent_steps_trained': 196245, 'num_env_steps_sampled': 196245, 'num_env_steps_trained': 196245, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 196245, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 196245, 'timers': {'training_iteration_time_ms': 5632.367, 'load_time_ms': 10.355, 'load_throughput': 386776.96, 'learn_time_ms': 4485.816, 'learn_throughput': 892.814, 'synch_weights_time_ms': 3.028}, 'counters': {'num_env_steps_sampled': 196245, 'num_env_steps_trained': 196245, 'num_agent_steps_sampled': 196245, 'num_agent_steps_trained': 196245}, 'done': False, 'episodes_total': 63, 'training_iteration': 49, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-58-56', 'timestamp': 1669852736, 'time_this_iter_s': 5.655445337295532, 'time_total_s': 277.058629989624, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 277.058629989624, 'timesteps_since_restore': 0, 'iterations_since_restore': 49, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.4125, 'ram_util_percent': 24.2}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 21.111873334680272, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.666746735316451, 'policy_loss': -0.021827971723471437, 'vf_loss': 9.688544695864442, 'vf_explained_var': -0.7088553005649197, 'kl': 0.015999187701632948, 'entropy': 0.6696734281637335, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 200250, 'num_env_steps_trained': 200250, 'num_agent_steps_sampled': 200250, 'num_agent_steps_trained': 200250}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 200250, 'num_agent_steps_trained': 200250, 'num_env_steps_sampled': 200250, 'num_env_steps_trained': 200250, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 200250, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 200250, 'timers': {'training_iteration_time_ms': 5630.431, 'load_time_ms': 9.915, 'load_throughput': 403951.153, 'learn_time_ms': 4489.56, 'learn_throughput': 892.07, 'synch_weights_time_ms': 3.018}, 'counters': {'num_env_steps_sampled': 200250, 'num_env_steps_trained': 200250, 'num_agent_steps_sampled': 200250, 'num_agent_steps_trained': 200250}, 'done': False, 'episodes_total': 63, 'training_iteration': 50, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-02', 'timestamp': 1669852742, 'time_this_iter_s': 5.557616233825684, 'time_total_s': 282.6162462234497, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 282.6162462234497, 'timesteps_since_restore': 0, 'iterations_since_restore': 50, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.099999999999998, 'ram_util_percent': 24.3}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 312.71051117677985, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.630896402943518, 'policy_loss': -0.008813169683700287, 'vf_loss': 8.639692241818674, 'vf_explained_var': -0.9997203360321701, 'kl': 0.009239343091669749, 'entropy': 0.654099513317949, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 204255, 'num_env_steps_trained': 204255, 'num_agent_steps_sampled': 204255, 'num_agent_steps_trained': 204255}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1263.4743782916423, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42728095942022215, 'mean_inference_ms': 1.195978351624557, 'mean_action_processing_ms': 0.06927889574744948, 'mean_env_wait_ms': 0.3225977359847583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 204255, 'num_agent_steps_trained': 204255, 'num_env_steps_sampled': 204255, 'num_env_steps_trained': 204255, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 204255, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 204255, 'timers': {'training_iteration_time_ms': 5626.565, 'load_time_ms': 9.886, 'load_throughput': 405099.683, 'learn_time_ms': 4500.594, 'learn_throughput': 889.883, 'synch_weights_time_ms': 2.993}, 'counters': {'num_env_steps_sampled': 204255, 'num_env_steps_trained': 204255, 'num_agent_steps_sampled': 204255, 'num_agent_steps_trained': 204255}, 'done': False, 'episodes_total': 63, 'training_iteration': 51, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-08', 'timestamp': 1669852748, 'time_this_iter_s': 5.739567279815674, 'time_total_s': 288.3558135032654, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 288.3558135032654, 'timesteps_since_restore': 0, 'iterations_since_restore': 51, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.775, 'ram_util_percent': 24.2125}}\n",
      "Checkpoint saved to /home/codespace/ray_results/PPO_EPANETEnv_2022-11-30_23-54-074nspqvxo/checkpoint_000051\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.83701928136169, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.503148599850235, 'policy_loss': 0.011619069409226218, 'vf_loss': 9.491493253297703, 'vf_explained_var': -0.8192246670364052, 'kl': 0.019341872179751196, 'entropy': 0.6072607597676657, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 208260, 'num_env_steps_trained': 208260, 'num_agent_steps_sampled': 208260, 'num_agent_steps_trained': 208260}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 208260, 'num_agent_steps_trained': 208260, 'num_env_steps_sampled': 208260, 'num_env_steps_trained': 208260, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 208260, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 208260, 'timers': {'training_iteration_time_ms': 5629.079, 'load_time_ms': 9.519, 'load_throughput': 420753.067, 'learn_time_ms': 4506.959, 'learn_throughput': 888.626, 'synch_weights_time_ms': 3.052}, 'counters': {'num_env_steps_sampled': 208260, 'num_env_steps_trained': 208260, 'num_agent_steps_sampled': 208260, 'num_agent_steps_trained': 208260}, 'done': False, 'episodes_total': 72, 'training_iteration': 52, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-13', 'timestamp': 1669852753, 'time_this_iter_s': 5.573949098587036, 'time_total_s': 293.9297626018524, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 293.9297626018524, 'timesteps_since_restore': 0, 'iterations_since_restore': 52, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.674999999999997, 'ram_util_percent': 24.35}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.581853527359424, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.609468186286188, 'policy_loss': -0.018873788560590438, 'vf_loss': 9.628323550890851, 'vf_explained_var': -0.652222050838573, 'kl': 0.009808240793399382, 'entropy': 0.6506096024026153, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 212265, 'num_env_steps_trained': 212265, 'num_agent_steps_sampled': 212265, 'num_agent_steps_trained': 212265}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 212265, 'num_agent_steps_trained': 212265, 'num_env_steps_sampled': 212265, 'num_env_steps_trained': 212265, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 212265, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 212265, 'timers': {'training_iteration_time_ms': 5626.714, 'load_time_ms': 9.516, 'load_throughput': 420848.992, 'learn_time_ms': 4510.883, 'learn_throughput': 887.853, 'synch_weights_time_ms': 3.036}, 'counters': {'num_env_steps_sampled': 212265, 'num_env_steps_trained': 212265, 'num_agent_steps_sampled': 212265, 'num_agent_steps_trained': 212265}, 'done': False, 'episodes_total': 72, 'training_iteration': 53, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-19', 'timestamp': 1669852759, 'time_this_iter_s': 5.6356916427612305, 'time_total_s': 299.56545424461365, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 299.56545424461365, 'timesteps_since_restore': 0, 'iterations_since_restore': 53, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.55, 'ram_util_percent': 24.325000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 154.38609754834525, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.02367769005478, 'policy_loss': -0.00011937128460054756, 'vf_loss': 9.023783561234833, 'vf_explained_var': -0.571019277393177, 'kl': 0.007180240771910621, 'entropy': 0.4909296440821822, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 216270, 'num_env_steps_trained': 216270, 'num_agent_steps_sampled': 216270, 'num_agent_steps_trained': 216270}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 216270, 'num_agent_steps_trained': 216270, 'num_env_steps_sampled': 216270, 'num_env_steps_trained': 216270, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 216270, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 216270, 'timers': {'training_iteration_time_ms': 5668.764, 'load_time_ms': 9.927, 'load_throughput': 403445.69, 'learn_time_ms': 4526.623, 'learn_throughput': 884.765, 'synch_weights_time_ms': 3.043}, 'counters': {'num_env_steps_sampled': 216270, 'num_env_steps_trained': 216270, 'num_agent_steps_sampled': 216270, 'num_agent_steps_trained': 216270}, 'done': False, 'episodes_total': 72, 'training_iteration': 54, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-25', 'timestamp': 1669852765, 'time_this_iter_s': 5.8942365646362305, 'time_total_s': 305.4596908092499, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 305.4596908092499, 'timesteps_since_restore': 0, 'iterations_since_restore': 54, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.4, 'ram_util_percent': 24.366666666666667}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.714287936326958, 'cur_kl_coeff': 0.0018771171569824214, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.932188146857806, 'policy_loss': 0.02200933346544863, 'vf_loss': 9.910170866853447, 'vf_explained_var': -0.05624103764052032, 'kl': 0.004235511528540091, 'entropy': 0.2599655077502292, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 220275, 'num_env_steps_trained': 220275, 'num_agent_steps_sampled': 220275, 'num_agent_steps_trained': 220275}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 220275, 'num_agent_steps_trained': 220275, 'num_env_steps_sampled': 220275, 'num_env_steps_trained': 220275, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 220275, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 220275, 'timers': {'training_iteration_time_ms': 5651.242, 'load_time_ms': 9.914, 'load_throughput': 403958.924, 'learn_time_ms': 4518.823, 'learn_throughput': 886.293, 'synch_weights_time_ms': 3.021}, 'counters': {'num_env_steps_sampled': 220275, 'num_env_steps_trained': 220275, 'num_agent_steps_sampled': 220275, 'num_agent_steps_trained': 220275}, 'done': False, 'episodes_total': 72, 'training_iteration': 55, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-30', 'timestamp': 1669852770, 'time_this_iter_s': 5.614574193954468, 'time_total_s': 311.07426500320435, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 311.07426500320435, 'timesteps_since_restore': 0, 'iterations_since_restore': 55, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.25, 'ram_util_percent': 24.4875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 104.44041959599701, 'cur_kl_coeff': 0.0009385585784912107, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.082099663313999, 'policy_loss': -0.008555322356762424, 'vf_loss': 9.090653499992944, 'vf_explained_var': -0.7093984347517772, 'kl': 0.0015982626502808917, 'entropy': 0.5968717388568386, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 224280, 'num_env_steps_trained': 224280, 'num_agent_steps_sampled': 224280, 'num_agent_steps_trained': 224280}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 224280, 'num_agent_steps_trained': 224280, 'num_env_steps_sampled': 224280, 'num_env_steps_trained': 224280, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 224280, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 224280, 'timers': {'training_iteration_time_ms': 5675.825, 'load_time_ms': 9.972, 'load_throughput': 401638.948, 'learn_time_ms': 4529.895, 'learn_throughput': 884.126, 'synch_weights_time_ms': 3.036}, 'counters': {'num_env_steps_sampled': 224280, 'num_env_steps_trained': 224280, 'num_agent_steps_sampled': 224280, 'num_agent_steps_trained': 224280}, 'done': False, 'episodes_total': 72, 'training_iteration': 56, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-36', 'timestamp': 1669852776, 'time_this_iter_s': 5.853288888931274, 'time_total_s': 316.9275538921356, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 316.9275538921356, 'timesteps_since_restore': 0, 'iterations_since_restore': 56, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.15, 'ram_util_percent': 24.525}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.536877181837635, 'cur_kl_coeff': 0.00046927928924560535, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.912212288764215, 'policy_loss': 0.023495033388376555, 'vf_loss': 9.888714541158368, 'vf_explained_var': 0.12840368318301376, 'kl': 0.005807068548022838, 'entropy': 0.44163748859077373, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 228285, 'num_env_steps_trained': 228285, 'num_agent_steps_sampled': 228285, 'num_agent_steps_trained': 228285}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 228285, 'num_agent_steps_trained': 228285, 'num_env_steps_sampled': 228285, 'num_env_steps_trained': 228285, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 228285, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 228285, 'timers': {'training_iteration_time_ms': 5675.23, 'load_time_ms': 9.554, 'load_throughput': 419212.682, 'learn_time_ms': 4524.713, 'learn_throughput': 885.139, 'synch_weights_time_ms': 3.035}, 'counters': {'num_env_steps_sampled': 228285, 'num_env_steps_trained': 228285, 'num_agent_steps_sampled': 228285, 'num_agent_steps_trained': 228285}, 'done': False, 'episodes_total': 72, 'training_iteration': 57, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-42', 'timestamp': 1669852782, 'time_this_iter_s': 5.715702056884766, 'time_total_s': 322.6432559490204, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 322.6432559490204, 'timesteps_since_restore': 0, 'iterations_since_restore': 57, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.962500000000002, 'ram_util_percent': 24.4625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.704854506630731, 'cur_kl_coeff': 0.00046927928924560535, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.963444416497344, 'policy_loss': 0.025994746788575124, 'vf_loss': 9.937449303493706, 'vf_explained_var': 0.06895303617241562, 'kl': 0.0008810207483545431, 'entropy': 0.1970829103903104, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 232290, 'num_env_steps_trained': 232290, 'num_agent_steps_sampled': 232290, 'num_agent_steps_trained': 232290}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1250.9243295768554, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42727783483633, 'mean_inference_ms': 1.1956585369938286, 'mean_action_processing_ms': 0.06922438214109485, 'mean_env_wait_ms': 0.3221902897166746, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 232290, 'num_agent_steps_trained': 232290, 'num_env_steps_sampled': 232290, 'num_env_steps_trained': 232290, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 232290, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 232290, 'timers': {'training_iteration_time_ms': 5701.524, 'load_time_ms': 9.588, 'load_throughput': 417702.229, 'learn_time_ms': 4534.74, 'learn_throughput': 883.182, 'synch_weights_time_ms': 3.042}, 'counters': {'num_env_steps_sampled': 232290, 'num_env_steps_trained': 232290, 'num_agent_steps_sampled': 232290, 'num_agent_steps_trained': 232290}, 'done': False, 'episodes_total': 72, 'training_iteration': 58, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-48', 'timestamp': 1669852788, 'time_this_iter_s': 5.833629846572876, 'time_total_s': 328.47688579559326, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 328.47688579559326, 'timesteps_since_restore': 0, 'iterations_since_restore': 58, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.1, 'ram_util_percent': 24.455555555555556}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.825071974987946, 'cur_kl_coeff': 0.00023463964462280267, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.851907531164025, 'policy_loss': -0.007106939953080909, 'vf_loss': 9.859004988721622, 'vf_explained_var': -0.5491297675717262, 'kl': 0.04034775875286033, 'entropy': 0.607153551969477, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 236295, 'num_env_steps_trained': 236295, 'num_agent_steps_sampled': 236295, 'num_agent_steps_trained': 236295}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 236295, 'num_agent_steps_trained': 236295, 'num_env_steps_sampled': 236295, 'num_env_steps_trained': 236295, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 236295, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 236295, 'timers': {'training_iteration_time_ms': 5693.767, 'load_time_ms': 9.586, 'load_throughput': 417812.355, 'learn_time_ms': 4521.041, 'learn_throughput': 885.858, 'synch_weights_time_ms': 3.043}, 'counters': {'num_env_steps_sampled': 236295, 'num_env_steps_trained': 236295, 'num_agent_steps_sampled': 236295, 'num_agent_steps_trained': 236295}, 'done': False, 'episodes_total': 81, 'training_iteration': 59, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-53', 'timestamp': 1669852793, 'time_this_iter_s': 5.57849907875061, 'time_total_s': 334.0553848743439, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 334.0553848743439, 'timesteps_since_restore': 0, 'iterations_since_restore': 59, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.825, 'ram_util_percent': 24.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 23.373407561043578, 'cur_kl_coeff': 0.000351959466934204, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.921617944650752, 'policy_loss': -0.008899068135407664, 'vf_loss': 9.930514753313474, 'vf_explained_var': -0.7416070986819524, 'kl': 0.006442560526162252, 'entropy': 0.6895975091124094, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 240300, 'num_env_steps_trained': 240300, 'num_agent_steps_sampled': 240300, 'num_agent_steps_trained': 240300}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 240300, 'num_agent_steps_trained': 240300, 'num_env_steps_sampled': 240300, 'num_env_steps_trained': 240300, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 240300, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 240300, 'timers': {'training_iteration_time_ms': 5712.946, 'load_time_ms': 9.642, 'load_throughput': 415378.258, 'learn_time_ms': 4526.043, 'learn_throughput': 884.879, 'synch_weights_time_ms': 3.027}, 'counters': {'num_env_steps_sampled': 240300, 'num_env_steps_trained': 240300, 'num_agent_steps_sampled': 240300, 'num_agent_steps_trained': 240300}, 'done': False, 'episodes_total': 81, 'training_iteration': 60, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-11-30_23-59-59', 'timestamp': 1669852799, 'time_this_iter_s': 5.7503345012664795, 'time_total_s': 339.80571937561035, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 339.80571937561035, 'timesteps_since_restore': 0, 'iterations_since_restore': 60, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.225, 'ram_util_percent': 24.575}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1317.4868101527554, 'cur_kl_coeff': 0.000351959466934204, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.095975218857489, 'policy_loss': 0.007673008972278205, 'vf_loss': 7.088296134561621, 'vf_explained_var': -0.006490312789076118, 'kl': 0.017321559788100807, 'entropy': 0.6854251468053428, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 244305, 'num_env_steps_trained': 244305, 'num_agent_steps_sampled': 244305, 'num_agent_steps_trained': 244305}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 244305, 'num_agent_steps_trained': 244305, 'num_env_steps_sampled': 244305, 'num_env_steps_trained': 244305, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 244305, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 244305, 'timers': {'training_iteration_time_ms': 5712.532, 'load_time_ms': 10.586, 'load_throughput': 378329.036, 'learn_time_ms': 4524.04, 'learn_throughput': 885.271, 'synch_weights_time_ms': 3.03}, 'counters': {'num_env_steps_sampled': 244305, 'num_env_steps_trained': 244305, 'num_agent_steps_sampled': 244305, 'num_agent_steps_trained': 244305}, 'done': False, 'episodes_total': 81, 'training_iteration': 61, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-05', 'timestamp': 1669852805, 'time_this_iter_s': 5.73414421081543, 'time_total_s': 345.5398635864258, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 345.5398635864258, 'timesteps_since_restore': 0, 'iterations_since_restore': 61, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.1375, 'ram_util_percent': 24.625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 21.896247441377692, 'cur_kl_coeff': 0.000351959466934204, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.80738188938428, 'policy_loss': 0.0006420323124495886, 'vf_loss': 9.806733962028257, 'vf_explained_var': -0.9942920569450625, 'kl': 0.016867409480597083, 'entropy': 0.6627850279372226, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 248310, 'num_env_steps_trained': 248310, 'num_agent_steps_sampled': 248310, 'num_agent_steps_trained': 248310}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 248310, 'num_agent_steps_trained': 248310, 'num_env_steps_sampled': 248310, 'num_env_steps_trained': 248310, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 248310, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 248310, 'timers': {'training_iteration_time_ms': 5732.671, 'load_time_ms': 10.576, 'load_throughput': 378677.001, 'learn_time_ms': 4523.36, 'learn_throughput': 885.404, 'synch_weights_time_ms': 3.001}, 'counters': {'num_env_steps_sampled': 248310, 'num_env_steps_trained': 248310, 'num_agent_steps_sampled': 248310, 'num_agent_steps_trained': 248310}, 'done': False, 'episodes_total': 81, 'training_iteration': 62, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-11', 'timestamp': 1669852811, 'time_this_iter_s': 5.776217222213745, 'time_total_s': 351.3160808086395, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 351.3160808086395, 'timesteps_since_restore': 0, 'iterations_since_restore': 62, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.325000000000003, 'ram_util_percent': 24.625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 436.4363883568074, 'cur_kl_coeff': 0.000351959466934204, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 6.622410290343787, 'policy_loss': -0.008663874768441724, 'vf_loss': 6.63106407585644, 'vf_explained_var': -0.4764407668062436, 'kl': 0.02874569236633356, 'entropy': 0.6778040164260454, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 252315, 'num_env_steps_trained': 252315, 'num_agent_steps_sampled': 252315, 'num_agent_steps_trained': 252315}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 252315, 'num_agent_steps_trained': 252315, 'num_env_steps_sampled': 252315, 'num_env_steps_trained': 252315, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 252315, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 252315, 'timers': {'training_iteration_time_ms': 5748.639, 'load_time_ms': 11.013, 'load_throughput': 363667.977, 'learn_time_ms': 4537.131, 'learn_throughput': 882.716, 'synch_weights_time_ms': 3.026}, 'counters': {'num_env_steps_sampled': 252315, 'num_env_steps_trained': 252315, 'num_agent_steps_sampled': 252315, 'num_agent_steps_trained': 252315}, 'done': False, 'episodes_total': 81, 'training_iteration': 63, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-17', 'timestamp': 1669852817, 'time_this_iter_s': 5.794034481048584, 'time_total_s': 357.1101152896881, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 357.1101152896881, 'timesteps_since_restore': 0, 'iterations_since_restore': 63, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.988888888888887, 'ram_util_percent': 24.644444444444442}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.549605763793712, 'cur_kl_coeff': 0.0005279392004013063, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.814157389056298, 'policy_loss': 0.023491166466947204, 'vf_loss': 9.790660963776292, 'vf_explained_var': 0.12499400877183484, 'kl': 0.009889209541315606, 'entropy': 0.5851310265961513, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 256320, 'num_env_steps_trained': 256320, 'num_agent_steps_sampled': 256320, 'num_agent_steps_trained': 256320}, 'sampler_results': {'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1560.4311061152555, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1253.4910239633862, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4275056739655638, 'mean_inference_ms': 1.19567311684495, 'mean_action_processing_ms': 0.06919945302783537, 'mean_env_wait_ms': 0.32195000799081563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 256320, 'num_agent_steps_trained': 256320, 'num_env_steps_sampled': 256320, 'num_env_steps_trained': 256320, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 256320, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 256320, 'timers': {'training_iteration_time_ms': 5748.46, 'load_time_ms': 10.715, 'load_throughput': 373777.305, 'learn_time_ms': 4535.362, 'learn_throughput': 883.061, 'synch_weights_time_ms': 3.109}, 'counters': {'num_env_steps_sampled': 256320, 'num_env_steps_trained': 256320, 'num_agent_steps_sampled': 256320, 'num_agent_steps_trained': 256320}, 'done': False, 'episodes_total': 81, 'training_iteration': 64, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-22', 'timestamp': 1669852822, 'time_this_iter_s': 5.893917083740234, 'time_total_s': 363.00403237342834, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 363.00403237342834, 'timesteps_since_restore': 0, 'iterations_since_restore': 64, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.85, 'ram_util_percent': 24.674999999999997}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 15.536910141860286, 'cur_kl_coeff': 0.0005279392004013063, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.815714092152094, 'policy_loss': 0.0008696465402521112, 'vf_loss': 9.814805121062903, 'vf_explained_var': -0.8443954613900954, 'kl': 0.07450822676923238, 'entropy': 0.6452458248343519, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 260325, 'num_env_steps_trained': 260325, 'num_agent_steps_sampled': 260325, 'num_agent_steps_trained': 260325}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 260325, 'num_agent_steps_trained': 260325, 'num_env_steps_sampled': 260325, 'num_env_steps_trained': 260325, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 260325, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 260325, 'timers': {'training_iteration_time_ms': 5740.98, 'load_time_ms': 10.837, 'load_throughput': 369566.186, 'learn_time_ms': 4527.969, 'learn_throughput': 884.503, 'synch_weights_time_ms': 3.115}, 'counters': {'num_env_steps_sampled': 260325, 'num_env_steps_trained': 260325, 'num_agent_steps_sampled': 260325, 'num_agent_steps_trained': 260325}, 'done': False, 'episodes_total': 90, 'training_iteration': 65, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-28', 'timestamp': 1669852828, 'time_this_iter_s': 5.538380146026611, 'time_total_s': 368.54241251945496, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 368.54241251945496, 'timesteps_since_restore': 0, 'iterations_since_restore': 65, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.75, 'ram_util_percent': 24.7875}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.227231779084691, 'cur_kl_coeff': 0.000791908800601959, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.668508111276934, 'policy_loss': -0.021758419804034694, 'vf_loss': 9.690250582336098, 'vf_explained_var': -0.7326568892566107, 'kl': 0.02011064849580947, 'entropy': 0.6822320033145207, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 264330, 'num_env_steps_trained': 264330, 'num_agent_steps_sampled': 264330, 'num_agent_steps_trained': 264330}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 264330, 'num_agent_steps_trained': 264330, 'num_env_steps_sampled': 264330, 'num_env_steps_trained': 264330, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 264330, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 264330, 'timers': {'training_iteration_time_ms': 5741.345, 'load_time_ms': 10.473, 'load_throughput': 382414.056, 'learn_time_ms': 4544.603, 'learn_throughput': 881.265, 'synch_weights_time_ms': 3.106}, 'counters': {'num_env_steps_sampled': 264330, 'num_env_steps_trained': 264330, 'num_agent_steps_sampled': 264330, 'num_agent_steps_trained': 264330}, 'done': False, 'episodes_total': 90, 'training_iteration': 66, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-34', 'timestamp': 1669852834, 'time_this_iter_s': 5.856705904006958, 'time_total_s': 374.3991184234619, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 374.3991184234619, 'timesteps_since_restore': 0, 'iterations_since_restore': 66, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.0625, 'ram_util_percent': 24.825000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 41.43975475184539, 'cur_kl_coeff': 0.0011878632009029388, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.375705432891845, 'policy_loss': 0.00641213556531296, 'vf_loss': 9.369288053307482, 'vf_explained_var': -0.4914159426125147, 'kl': 0.004439095212885733, 'entropy': 0.6569881377040699, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 268335, 'num_env_steps_trained': 268335, 'num_agent_steps_sampled': 268335, 'num_agent_steps_trained': 268335}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 268335, 'num_agent_steps_trained': 268335, 'num_env_steps_sampled': 268335, 'num_env_steps_trained': 268335, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 268335, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 268335, 'timers': {'training_iteration_time_ms': 5735.221, 'load_time_ms': 10.48, 'load_throughput': 382143.499, 'learn_time_ms': 4536.872, 'learn_throughput': 882.767, 'synch_weights_time_ms': 3.15}, 'counters': {'num_env_steps_sampled': 268335, 'num_env_steps_trained': 268335, 'num_agent_steps_sampled': 268335, 'num_agent_steps_trained': 268335}, 'done': False, 'episodes_total': 90, 'training_iteration': 67, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-40', 'timestamp': 1669852840, 'time_this_iter_s': 5.6544764041900635, 'time_total_s': 380.053594827652, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 380.053594827652, 'timesteps_since_restore': 0, 'iterations_since_restore': 67, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.5125, 'ram_util_percent': 24.8125}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.547217727901154, 'cur_kl_coeff': 0.0005939316004514694, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.617463408747026, 'policy_loss': 0.018095483009012477, 'vf_loss': 9.599366515169862, 'vf_explained_var': -0.5543492876073366, 'kl': 0.0024320592311421587, 'entropy': 0.6486661680923995, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 272340, 'num_env_steps_trained': 272340, 'num_agent_steps_sampled': 272340, 'num_agent_steps_trained': 272340}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 272340, 'num_agent_steps_trained': 272340, 'num_env_steps_sampled': 272340, 'num_env_steps_trained': 272340, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 272340, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 272340, 'timers': {'training_iteration_time_ms': 5725.029, 'load_time_ms': 10.496, 'load_throughput': 381561.927, 'learn_time_ms': 4552.561, 'learn_throughput': 879.725, 'synch_weights_time_ms': 3.174}, 'counters': {'num_env_steps_sampled': 272340, 'num_env_steps_trained': 272340, 'num_agent_steps_sampled': 272340, 'num_agent_steps_trained': 272340}, 'done': False, 'episodes_total': 90, 'training_iteration': 68, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-45', 'timestamp': 1669852845, 'time_this_iter_s': 5.731558322906494, 'time_total_s': 385.7851531505585, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 385.7851531505585, 'timesteps_since_restore': 0, 'iterations_since_restore': 68, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.58888888888889, 'ram_util_percent': 24.944444444444443}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 94.45856083277413, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.282160038076421, 'policy_loss': -0.015392090592493293, 'vf_loss': 8.29754991582645, 'vf_explained_var': 0.36513731505281183, 'kl': 0.007600916161814981, 'entropy': 0.6820500859009322, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 276345, 'num_env_steps_trained': 276345, 'num_agent_steps_sampled': 276345, 'num_agent_steps_trained': 276345}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 276345, 'num_agent_steps_trained': 276345, 'num_env_steps_sampled': 276345, 'num_env_steps_trained': 276345, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 276345, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 276345, 'timers': {'training_iteration_time_ms': 5737.877, 'load_time_ms': 10.585, 'load_throughput': 378373.349, 'learn_time_ms': 4557.313, 'learn_throughput': 878.807, 'synch_weights_time_ms': 3.181}, 'counters': {'num_env_steps_sampled': 276345, 'num_env_steps_trained': 276345, 'num_agent_steps_sampled': 276345, 'num_agent_steps_trained': 276345}, 'done': False, 'episodes_total': 90, 'training_iteration': 69, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-51', 'timestamp': 1669852851, 'time_this_iter_s': 5.705717325210571, 'time_total_s': 391.49087047576904, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 391.49087047576904, 'timesteps_since_restore': 0, 'iterations_since_restore': 69, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.4375, 'ram_util_percent': 25.275}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.722701097736436, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.892279611608034, 'policy_loss': 0.022675963607366366, 'vf_loss': 9.869601936750515, 'vf_explained_var': 0.0714531486393303, 'kl': 0.005801046229127284, 'entropy': 0.5731068280435377, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 280350, 'num_env_steps_trained': 280350, 'num_agent_steps_sampled': 280350, 'num_agent_steps_trained': 280350}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 280350, 'num_agent_steps_trained': 280350, 'num_env_steps_sampled': 280350, 'num_env_steps_trained': 280350, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 280350, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 280350, 'timers': {'training_iteration_time_ms': 5748.015, 'load_time_ms': 10.605, 'load_throughput': 377668.981, 'learn_time_ms': 4573.831, 'learn_throughput': 875.634, 'synch_weights_time_ms': 3.169}, 'counters': {'num_env_steps_sampled': 280350, 'num_env_steps_trained': 280350, 'num_agent_steps_sampled': 280350, 'num_agent_steps_trained': 280350}, 'done': False, 'episodes_total': 90, 'training_iteration': 70, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-00-57', 'timestamp': 1669852857, 'time_this_iter_s': 5.851055145263672, 'time_total_s': 397.3419256210327, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 397.3419256210327, 'timesteps_since_restore': 0, 'iterations_since_restore': 70, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.1625, 'ram_util_percent': 25.5375}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.019028567715037, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.92550701736122, 'policy_loss': 0.022555735861502026, 'vf_loss': 9.902948231850901, 'vf_explained_var': 0.2093070283371915, 'kl': 0.010342115444221684, 'entropy': 0.4113566687991542, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 284355, 'num_env_steps_trained': 284355, 'num_agent_steps_sampled': 284355, 'num_agent_steps_trained': 284355}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1282.4504598465185, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42782675869592846, 'mean_inference_ms': 1.195723315758107, 'mean_action_processing_ms': 0.06917626667332566, 'mean_env_wait_ms': 0.3217447463651232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 284355, 'num_agent_steps_trained': 284355, 'num_env_steps_sampled': 284355, 'num_env_steps_trained': 284355, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 284355, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 284355, 'timers': {'training_iteration_time_ms': 5751.322, 'load_time_ms': 10.027, 'load_throughput': 399434.727, 'learn_time_ms': 4577.679, 'learn_throughput': 874.898, 'synch_weights_time_ms': 3.162}, 'counters': {'num_env_steps_sampled': 284355, 'num_env_steps_trained': 284355, 'num_agent_steps_sampled': 284355, 'num_agent_steps_trained': 284355}, 'done': False, 'episodes_total': 90, 'training_iteration': 71, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-03', 'timestamp': 1669852863, 'time_this_iter_s': 5.766586780548096, 'time_total_s': 403.1085124015808, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 403.1085124015808, 'timesteps_since_restore': 0, 'iterations_since_restore': 71, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.25, 'ram_util_percent': 25.7875}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.658851474587635, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.875518650136968, 'policy_loss': 0.0003047533012846465, 'vf_loss': 9.875212229451826, 'vf_explained_var': -0.6413909471804096, 'kl': 0.005597354401006223, 'entropy': 0.5851844860020504, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 288360, 'num_env_steps_trained': 288360, 'num_agent_steps_sampled': 288360, 'num_agent_steps_trained': 288360}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 288360, 'num_agent_steps_trained': 288360, 'num_env_steps_sampled': 288360, 'num_env_steps_trained': 288360, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 288360, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 288360, 'timers': {'training_iteration_time_ms': 5747.063, 'load_time_ms': 10.055, 'load_throughput': 398309.551, 'learn_time_ms': 4585.127, 'learn_throughput': 873.476, 'synch_weights_time_ms': 3.207}, 'counters': {'num_env_steps_sampled': 288360, 'num_env_steps_trained': 288360, 'num_agent_steps_sampled': 288360, 'num_agent_steps_trained': 288360}, 'done': False, 'episodes_total': 99, 'training_iteration': 72, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-08', 'timestamp': 1669852868, 'time_this_iter_s': 5.734010696411133, 'time_total_s': 408.84252309799194, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 408.84252309799194, 'timesteps_since_restore': 0, 'iterations_since_restore': 72, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.055555555555557, 'ram_util_percent': 26.200000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 126.77089070512723, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.304092310833674, 'policy_loss': -0.006946691173699594, 'vf_loss': 9.311034037989955, 'vf_explained_var': -0.923024074492916, 'kl': 0.016862846646332794, 'entropy': 0.6733337776635283, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 292365, 'num_env_steps_trained': 292365, 'num_agent_steps_sampled': 292365, 'num_agent_steps_trained': 292365}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 292365, 'num_agent_steps_trained': 292365, 'num_env_steps_sampled': 292365, 'num_env_steps_trained': 292365, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 292365, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 292365, 'timers': {'training_iteration_time_ms': 5741.104, 'load_time_ms': 10.073, 'load_throughput': 397608.118, 'learn_time_ms': 4573.87, 'learn_throughput': 875.626, 'synch_weights_time_ms': 3.215}, 'counters': {'num_env_steps_sampled': 292365, 'num_env_steps_trained': 292365, 'num_agent_steps_sampled': 292365, 'num_agent_steps_trained': 292365}, 'done': False, 'episodes_total': 99, 'training_iteration': 73, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-14', 'timestamp': 1669852874, 'time_this_iter_s': 5.736577272415161, 'time_total_s': 414.5791003704071, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 414.5791003704071, 'timesteps_since_restore': 0, 'iterations_since_restore': 73, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.5875, 'ram_util_percent': 26.4625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 17.6553179262947, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.936714576393046, 'policy_loss': 0.025261159669808162, 'vf_loss': 9.911449481594946, 'vf_explained_var': 0.2638967194864827, 'kl': 0.01313545250289056, 'entropy': 0.6768565112544644, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 296370, 'num_env_steps_trained': 296370, 'num_agent_steps_sampled': 296370, 'num_agent_steps_trained': 296370}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 296370, 'num_agent_steps_trained': 296370, 'num_env_steps_sampled': 296370, 'num_env_steps_trained': 296370, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 296370, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 296370, 'timers': {'training_iteration_time_ms': 5713.022, 'load_time_ms': 9.956, 'load_throughput': 402267.008, 'learn_time_ms': 4576.286, 'learn_throughput': 875.164, 'synch_weights_time_ms': 3.184}, 'counters': {'num_env_steps_sampled': 296370, 'num_env_steps_trained': 296370, 'num_agent_steps_sampled': 296370, 'num_agent_steps_trained': 296370}, 'done': False, 'episodes_total': 99, 'training_iteration': 74, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-20', 'timestamp': 1669852880, 'time_this_iter_s': 5.6109843254089355, 'time_total_s': 420.19008469581604, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 420.19008469581604, 'timesteps_since_restore': 0, 'iterations_since_restore': 74, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.9375, 'ram_util_percent': 26.625}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 80.73670728501453, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.569895944826465, 'policy_loss': 0.005664026838356769, 'vf_loss': 8.56422900935655, 'vf_explained_var': -0.2965515955801933, 'kl': 0.009788692678076133, 'entropy': 0.6543485158233232, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 300375, 'num_env_steps_trained': 300375, 'num_agent_steps_sampled': 300375, 'num_agent_steps_trained': 300375}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 300375, 'num_agent_steps_trained': 300375, 'num_env_steps_sampled': 300375, 'num_env_steps_trained': 300375, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 300375, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 300375, 'timers': {'training_iteration_time_ms': 5775.572, 'load_time_ms': 9.873, 'load_throughput': 405653.378, 'learn_time_ms': 4620.776, 'learn_throughput': 866.738, 'synch_weights_time_ms': 3.217}, 'counters': {'num_env_steps_sampled': 300375, 'num_env_steps_trained': 300375, 'num_agent_steps_sampled': 300375, 'num_agent_steps_trained': 300375}, 'done': False, 'episodes_total': 99, 'training_iteration': 75, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-26', 'timestamp': 1669852886, 'time_this_iter_s': 6.163864850997925, 'time_total_s': 426.35394954681396, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 426.35394954681396, 'timesteps_since_restore': 0, 'iterations_since_restore': 75, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 29.5375, 'ram_util_percent': 27.125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 28.066285279809787, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.458572631753901, 'policy_loss': -0.00015558573587607313, 'vf_loss': 9.458724014733427, 'vf_explained_var': -0.1850740388516457, 'kl': 0.014114973099630794, 'entropy': 0.6328568403438856, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 304380, 'num_env_steps_trained': 304380, 'num_agent_steps_sampled': 304380, 'num_agent_steps_trained': 304380}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 304380, 'num_agent_steps_trained': 304380, 'num_env_steps_sampled': 304380, 'num_env_steps_trained': 304380, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 304380, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 304380, 'timers': {'training_iteration_time_ms': 5759.3, 'load_time_ms': 9.86, 'load_throughput': 406190.909, 'learn_time_ms': 4605.915, 'learn_throughput': 869.534, 'synch_weights_time_ms': 3.2}, 'counters': {'num_env_steps_sampled': 304380, 'num_env_steps_trained': 304380, 'num_agent_steps_sampled': 304380, 'num_agent_steps_trained': 304380}, 'done': False, 'episodes_total': 99, 'training_iteration': 76, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-32', 'timestamp': 1669852892, 'time_this_iter_s': 5.694377422332764, 'time_total_s': 432.04832696914673, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 432.04832696914673, 'timesteps_since_restore': 0, 'iterations_since_restore': 76, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.233333333333334, 'ram_util_percent': 27.544444444444444}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.05163462011404, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.889248509560861, 'policy_loss': 0.02472113299569095, 'vf_loss': 9.864525074087164, 'vf_explained_var': 0.24368991018623434, 'kl': 0.00779226499361001, 'entropy': 0.5068359312831715, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 308385, 'num_env_steps_trained': 308385, 'num_agent_steps_sampled': 308385, 'num_agent_steps_trained': 308385}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1241.3047287488016, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1259.6186925777206, 1263.6416856509677, 1243.2492387230477, 1269.5825383073527, 1282.0456116724918, 1248.190862316722, 1280.1814110097746, 1242.7918511743237, 1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4281377311291145, 'mean_inference_ms': 1.1959027543747784, 'mean_action_processing_ms': 0.06916754718848218, 'mean_env_wait_ms': 0.32162178581581186, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 308385, 'num_agent_steps_trained': 308385, 'num_env_steps_sampled': 308385, 'num_env_steps_trained': 308385, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 308385, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 308385, 'timers': {'training_iteration_time_ms': 5788.145, 'load_time_ms': 10.337, 'load_throughput': 387446.029, 'learn_time_ms': 4618.232, 'learn_throughput': 867.215, 'synch_weights_time_ms': 3.152}, 'counters': {'num_env_steps_sampled': 308385, 'num_env_steps_trained': 308385, 'num_agent_steps_sampled': 308385, 'num_agent_steps_trained': 308385}, 'done': False, 'episodes_total': 99, 'training_iteration': 77, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-38', 'timestamp': 1669852898, 'time_this_iter_s': 5.942641735076904, 'time_total_s': 437.99096870422363, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 437.99096870422363, 'timesteps_since_restore': 0, 'iterations_since_restore': 77, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.599999999999998, 'ram_util_percent': 27.85}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 14.800943592543243, 'cur_kl_coeff': 0.0002969658002257347, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.860734129464754, 'policy_loss': 0.004675519963105519, 'vf_loss': 9.856045136400448, 'vf_explained_var': -0.994911681323923, 'kl': 0.04535066874115159, 'entropy': 0.4907770927074135, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 312390, 'num_env_steps_trained': 312390, 'num_agent_steps_sampled': 312390, 'num_agent_steps_trained': 312390}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 312390, 'num_agent_steps_trained': 312390, 'num_env_steps_sampled': 312390, 'num_env_steps_trained': 312390, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 312390, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 312390, 'timers': {'training_iteration_time_ms': 5788.499, 'load_time_ms': 10.363, 'load_throughput': 386466.408, 'learn_time_ms': 4614.896, 'learn_throughput': 867.842, 'synch_weights_time_ms': 3.107}, 'counters': {'num_env_steps_sampled': 312390, 'num_env_steps_trained': 312390, 'num_agent_steps_sampled': 312390, 'num_agent_steps_trained': 312390}, 'done': False, 'episodes_total': 108, 'training_iteration': 78, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-43', 'timestamp': 1669852903, 'time_this_iter_s': 5.736037015914917, 'time_total_s': 443.72700572013855, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 443.72700572013855, 'timesteps_since_restore': 0, 'iterations_since_restore': 78, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 22.4625, 'ram_util_percent': 27.349999999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 185.8436662471102, 'cur_kl_coeff': 0.0004454487003386022, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.034799600416614, 'policy_loss': -0.013148157611008614, 'vf_loss': 9.047940354706139, 'vf_explained_var': -1.0, 'kl': 0.016608706350833422, 'entropy': 0.5544885501746208, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 316395, 'num_env_steps_trained': 316395, 'num_agent_steps_sampled': 316395, 'num_agent_steps_trained': 316395}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 316395, 'num_agent_steps_trained': 316395, 'num_env_steps_sampled': 316395, 'num_env_steps_trained': 316395, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 316395, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 316395, 'timers': {'training_iteration_time_ms': 5801.555, 'load_time_ms': 10.331, 'load_throughput': 387657.042, 'learn_time_ms': 4619.37, 'learn_throughput': 867.001, 'synch_weights_time_ms': 3.134}, 'counters': {'num_env_steps_sampled': 316395, 'num_env_steps_trained': 316395, 'num_agent_steps_sampled': 316395, 'num_agent_steps_trained': 316395}, 'done': False, 'episodes_total': 108, 'training_iteration': 79, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-49', 'timestamp': 1669852909, 'time_this_iter_s': 5.837871313095093, 'time_total_s': 449.56487703323364, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 449.56487703323364, 'timesteps_since_restore': 0, 'iterations_since_restore': 79, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.355555555555558, 'ram_util_percent': 25.444444444444443}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 20.28310077562127, 'cur_kl_coeff': 0.0004454487003386022, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.841578124159126, 'policy_loss': 0.019143279085075984, 'vf_loss': 9.822430560409382, 'vf_explained_var': -0.05831422664785898, 'kl': 0.009685311361712443, 'entropy': 0.5632719074205685, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 320400, 'num_env_steps_trained': 320400, 'num_agent_steps_sampled': 320400, 'num_agent_steps_trained': 320400}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 320400, 'num_agent_steps_trained': 320400, 'num_env_steps_sampled': 320400, 'num_env_steps_trained': 320400, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 320400, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 320400, 'timers': {'training_iteration_time_ms': 5787.161, 'load_time_ms': 10.711, 'load_throughput': 373931.232, 'learn_time_ms': 4604.628, 'learn_throughput': 869.777, 'synch_weights_time_ms': 3.164}, 'counters': {'num_env_steps_sampled': 320400, 'num_env_steps_trained': 320400, 'num_agent_steps_sampled': 320400, 'num_agent_steps_trained': 320400}, 'done': False, 'episodes_total': 108, 'training_iteration': 80, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-01-55', 'timestamp': 1669852915, 'time_this_iter_s': 5.7069315910339355, 'time_total_s': 455.2718086242676, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 455.2718086242676, 'timesteps_since_restore': 0, 'iterations_since_restore': 80, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.825, 'ram_util_percent': 25.525}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 14.364784610183328, 'cur_kl_coeff': 0.0004454487003386022, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.783241150968818, 'policy_loss': 0.024053116551330012, 'vf_loss': 9.7591812369644, 'vf_explained_var': -0.9986810125330443, 'kl': 0.015309674125096288, 'entropy': 0.6044110454859272, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 324405, 'num_env_steps_trained': 324405, 'num_agent_steps_sampled': 324405, 'num_agent_steps_trained': 324405}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 324405, 'num_agent_steps_trained': 324405, 'num_env_steps_sampled': 324405, 'num_env_steps_trained': 324405, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 324405, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 324405, 'timers': {'training_iteration_time_ms': 5785.032, 'load_time_ms': 10.373, 'load_throughput': 386083.576, 'learn_time_ms': 4606.795, 'learn_throughput': 869.368, 'synch_weights_time_ms': 3.185}, 'counters': {'num_env_steps_sampled': 324405, 'num_env_steps_trained': 324405, 'num_agent_steps_sampled': 324405, 'num_agent_steps_trained': 324405}, 'done': False, 'episodes_total': 108, 'training_iteration': 81, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-01', 'timestamp': 1669852921, 'time_this_iter_s': 5.746628522872925, 'time_total_s': 461.0184371471405, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 461.0184371471405, 'timesteps_since_restore': 0, 'iterations_since_restore': 81, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.3625, 'ram_util_percent': 25.725}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 221.192729424533, 'cur_kl_coeff': 0.0004454487003386022, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.801128997854007, 'policy_loss': -0.01580115180482627, 'vf_loss': 7.816912584920083, 'vf_explained_var': -0.2659022205619402, 'kl': 0.03939988401726884, 'entropy': 0.650864060912081, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 328410, 'num_env_steps_trained': 328410, 'num_agent_steps_sampled': 328410, 'num_agent_steps_trained': 328410}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 328410, 'num_agent_steps_trained': 328410, 'num_env_steps_sampled': 328410, 'num_env_steps_trained': 328410, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 328410, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 328410, 'timers': {'training_iteration_time_ms': 5783.392, 'load_time_ms': 10.496, 'load_throughput': 381590.53, 'learn_time_ms': 4613.057, 'learn_throughput': 868.188, 'synch_weights_time_ms': 3.112}, 'counters': {'num_env_steps_sampled': 328410, 'num_env_steps_trained': 328410, 'num_agent_steps_sampled': 328410, 'num_agent_steps_trained': 328410}, 'done': False, 'episodes_total': 108, 'training_iteration': 82, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-07', 'timestamp': 1669852927, 'time_this_iter_s': 5.718653678894043, 'time_total_s': 466.73709082603455, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 466.73709082603455, 'timesteps_since_restore': 0, 'iterations_since_restore': 82, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.15, 'ram_util_percent': 25.9125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.352052814537479, 'cur_kl_coeff': 0.0006681730505079031, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 10.0238171638981, 'policy_loss': 0.023827670254213836, 'vf_loss': 9.99998182788972, 'vf_explained_var': 0.14680974470671787, 'kl': 0.011515249570272966, 'entropy': 0.6170717256684457, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 332415, 'num_env_steps_trained': 332415, 'num_agent_steps_sampled': 332415, 'num_agent_steps_trained': 332415}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 332415, 'num_agent_steps_trained': 332415, 'num_env_steps_sampled': 332415, 'num_env_steps_trained': 332415, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 332415, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 332415, 'timers': {'training_iteration_time_ms': 5783.716, 'load_time_ms': 10.087, 'load_throughput': 397028.289, 'learn_time_ms': 4628.141, 'learn_throughput': 865.358, 'synch_weights_time_ms': 3.081}, 'counters': {'num_env_steps_sampled': 332415, 'num_env_steps_trained': 332415, 'num_agent_steps_sampled': 332415, 'num_agent_steps_trained': 332415}, 'done': False, 'episodes_total': 108, 'training_iteration': 83, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-12', 'timestamp': 1669852932, 'time_this_iter_s': 5.7390055656433105, 'time_total_s': 472.47609639167786, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 472.47609639167786, 'timesteps_since_restore': 0, 'iterations_since_restore': 83, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.1875, 'ram_util_percent': 26.0875}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.904341315321864, 'cur_kl_coeff': 0.0006681730505079031, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.960000572409681, 'policy_loss': 0.018819370070692672, 'vf_loss': 9.94117138462682, 'vf_explained_var': 0.1603405116065856, 'kl': 0.014738238463426126, 'entropy': 0.45168740925609424, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 336420, 'num_env_steps_trained': 336420, 'num_agent_steps_sampled': 336420, 'num_agent_steps_trained': 336420}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1232.418765590008, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1242.7674443211588, 1432.4474093426688, 1389.1960258451586, 1428.501382912189, 1395.9876506270493, 1439.5986295690984, 1365.3478280079173, 1451.9169684974831, 1377.5104145923312, 1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.42876982988426204, 'mean_inference_ms': 1.1969108375471993, 'mean_action_processing_ms': 0.06912772381865598, 'mean_env_wait_ms': 0.32121862081950164, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 336420, 'num_agent_steps_trained': 336420, 'num_env_steps_sampled': 336420, 'num_env_steps_trained': 336420, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 336420, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 336420, 'timers': {'training_iteration_time_ms': 5784.73, 'load_time_ms': 10.528, 'load_throughput': 380407.522, 'learn_time_ms': 4620.731, 'learn_throughput': 866.746, 'synch_weights_time_ms': 3.012}, 'counters': {'num_env_steps_sampled': 336420, 'num_env_steps_trained': 336420, 'num_agent_steps_sampled': 336420, 'num_agent_steps_trained': 336420}, 'done': False, 'episodes_total': 108, 'training_iteration': 84, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-18', 'timestamp': 1669852938, 'time_this_iter_s': 5.621016025543213, 'time_total_s': 478.09711241722107, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 478.09711241722107, 'timesteps_since_restore': 0, 'iterations_since_restore': 84, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.5625, 'ram_util_percent': 26.375}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.507223525787554, 'cur_kl_coeff': 0.0006681730505079031, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.8753156528678, 'policy_loss': -0.00022369884355093842, 'vf_loss': 9.875535226637318, 'vf_explained_var': -0.5244453564126005, 'kl': 0.00620299622945898, 'entropy': 0.5885351736699381, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 340425, 'num_env_steps_trained': 340425, 'num_agent_steps_sampled': 340425, 'num_agent_steps_trained': 340425}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 340425, 'num_agent_steps_trained': 340425, 'num_env_steps_sampled': 340425, 'num_env_steps_trained': 340425, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 340425, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 340425, 'timers': {'training_iteration_time_ms': 5760.288, 'load_time_ms': 10.56, 'load_throughput': 379263.506, 'learn_time_ms': 4608.154, 'learn_throughput': 869.112, 'synch_weights_time_ms': 2.995}, 'counters': {'num_env_steps_sampled': 340425, 'num_env_steps_trained': 340425, 'num_agent_steps_sampled': 340425, 'num_agent_steps_trained': 340425}, 'done': False, 'episodes_total': 117, 'training_iteration': 85, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-24', 'timestamp': 1669852944, 'time_this_iter_s': 5.919182538986206, 'time_total_s': 484.0162949562073, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 484.0162949562073, 'timesteps_since_restore': 0, 'iterations_since_restore': 85, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.833333333333332, 'ram_util_percent': 26.933333333333334}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 50.197778629006876, 'cur_kl_coeff': 0.0006681730505079031, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.417609953111217, 'policy_loss': 0.004097008221952986, 'vf_loss': 9.413511531583724, 'vf_explained_var': -0.6329698545958407, 'kl': 0.002166108321531839, 'entropy': 0.6326539758713015, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 344430, 'num_env_steps_trained': 344430, 'num_agent_steps_sampled': 344430, 'num_agent_steps_trained': 344430}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 344430, 'num_agent_steps_trained': 344430, 'num_env_steps_sampled': 344430, 'num_env_steps_trained': 344430, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 344430, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 344430, 'timers': {'training_iteration_time_ms': 5766.362, 'load_time_ms': 10.544, 'load_throughput': 379833.794, 'learn_time_ms': 4611.144, 'learn_throughput': 868.548, 'synch_weights_time_ms': 2.99}, 'counters': {'num_env_steps_sampled': 344430, 'num_env_steps_trained': 344430, 'num_agent_steps_sampled': 344430, 'num_agent_steps_trained': 344430}, 'done': False, 'episodes_total': 117, 'training_iteration': 86, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-30', 'timestamp': 1669852950, 'time_this_iter_s': 5.754822731018066, 'time_total_s': 489.77111768722534, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 489.77111768722534, 'timesteps_since_restore': 0, 'iterations_since_restore': 86, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.5875, 'ram_util_percent': 27.225}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 10.445728414119172, 'cur_kl_coeff': 0.00033408652525395154, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.958610545947987, 'policy_loss': 0.026009119554392755, 'vf_loss': 9.932600213122624, 'vf_explained_var': 0.6718286805255439, 'kl': 0.0037336352478562133, 'entropy': 0.5316689649576782, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 348435, 'num_env_steps_trained': 348435, 'num_agent_steps_sampled': 348435, 'num_agent_steps_trained': 348435}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 348435, 'num_agent_steps_trained': 348435, 'num_env_steps_sampled': 348435, 'num_env_steps_trained': 348435, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 348435, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 348435, 'timers': {'training_iteration_time_ms': 5760.656, 'load_time_ms': 10.169, 'load_throughput': 393856.755, 'learn_time_ms': 4626.088, 'learn_throughput': 865.742, 'synch_weights_time_ms': 3.01}, 'counters': {'num_env_steps_sampled': 348435, 'num_env_steps_trained': 348435, 'num_agent_steps_sampled': 348435, 'num_agent_steps_trained': 348435}, 'done': False, 'episodes_total': 117, 'training_iteration': 87, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-36', 'timestamp': 1669852956, 'time_this_iter_s': 5.885641813278198, 'time_total_s': 495.65675950050354, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 495.65675950050354, 'timesteps_since_restore': 0, 'iterations_since_restore': 87, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.75, 'ram_util_percent': 27.2125}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 220.78435682322709, 'cur_kl_coeff': 0.00016704326262697577, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 6.607910627829692, 'policy_loss': 0.006792293312729046, 'vf_loss': 6.601117006489026, 'vf_explained_var': -0.2558857262134552, 'kl': 0.008057574513635172, 'entropy': 0.5310605540390938, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 352440, 'num_env_steps_trained': 352440, 'num_agent_steps_sampled': 352440, 'num_agent_steps_trained': 352440}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 352440, 'num_agent_steps_trained': 352440, 'num_env_steps_sampled': 352440, 'num_env_steps_trained': 352440, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 352440, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 352440, 'timers': {'training_iteration_time_ms': 5760.558, 'load_time_ms': 10.154, 'load_throughput': 394440.316, 'learn_time_ms': 4620.676, 'learn_throughput': 866.756, 'synch_weights_time_ms': 3.02}, 'counters': {'num_env_steps_sampled': 352440, 'num_env_steps_trained': 352440, 'num_agent_steps_sampled': 352440, 'num_agent_steps_trained': 352440}, 'done': False, 'episodes_total': 117, 'training_iteration': 88, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-41', 'timestamp': 1669852961, 'time_this_iter_s': 5.7339558601379395, 'time_total_s': 501.3907153606415, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 501.3907153606415, 'timesteps_since_restore': 0, 'iterations_since_restore': 88, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.622222222222224, 'ram_util_percent': 25.355555555555554}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 13.047602786700573, 'cur_kl_coeff': 0.00016704326262697577, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.636554907214258, 'policy_loss': -0.00010528462308068429, 'vf_loss': 9.636656192041212, 'vf_explained_var': -0.6693059018863144, 'kl': 0.024021933484696795, 'entropy': 0.6902391890043853, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 356445, 'num_env_steps_trained': 356445, 'num_agent_steps_sampled': 356445, 'num_agent_steps_trained': 356445}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 356445, 'num_agent_steps_trained': 356445, 'num_env_steps_sampled': 356445, 'num_env_steps_trained': 356445, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 356445, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 356445, 'timers': {'training_iteration_time_ms': 5751.915, 'load_time_ms': 10.143, 'load_throughput': 394842.693, 'learn_time_ms': 4631.335, 'learn_throughput': 864.761, 'synch_weights_time_ms': 3.008}, 'counters': {'num_env_steps_sampled': 356445, 'num_env_steps_trained': 356445, 'num_agent_steps_sampled': 356445, 'num_agent_steps_trained': 356445}, 'done': False, 'episodes_total': 117, 'training_iteration': 89, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-47', 'timestamp': 1669852967, 'time_this_iter_s': 5.751274824142456, 'time_total_s': 507.14199018478394, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 507.14199018478394, 'timesteps_since_restore': 0, 'iterations_since_restore': 89, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.512500000000003, 'ram_util_percent': 25.4375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.940700581962222, 'cur_kl_coeff': 0.00025056489394046375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.949338315122871, 'policy_loss': 0.02049138652541304, 'vf_loss': 9.928841621645036, 'vf_explained_var': 0.38808642548899497, 'kl': 0.021260450985427073, 'entropy': 0.6655955200554222, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 360450, 'num_env_steps_trained': 360450, 'num_agent_steps_sampled': 360450, 'num_agent_steps_trained': 360450}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 329.0158268180805, 'episode_reward_mean': 1223.233049769895, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1406.1751963236536, 382.3392964813572, 363.53575031039105, 455.79780755460894, 329.0158268180805, 344.1715441244756, 409.04640945313514, 401.77429512555693, 448.53130635013787, 422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.429642634325279, 'mean_inference_ms': 1.1974082420500844, 'mean_action_processing_ms': 0.06911229340823496, 'mean_env_wait_ms': 0.3209275614818485, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 360450, 'num_agent_steps_trained': 360450, 'num_env_steps_sampled': 360450, 'num_env_steps_trained': 360450, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 360450, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 360450, 'timers': {'training_iteration_time_ms': 5781.813, 'load_time_ms': 10.222, 'load_throughput': 391820.049, 'learn_time_ms': 4658.964, 'learn_throughput': 859.633, 'synch_weights_time_ms': 2.992}, 'counters': {'num_env_steps_sampled': 360450, 'num_env_steps_trained': 360450, 'num_agent_steps_sampled': 360450, 'num_agent_steps_trained': 360450}, 'done': False, 'episodes_total': 117, 'training_iteration': 90, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-02-53', 'timestamp': 1669852973, 'time_this_iter_s': 6.009002447128296, 'time_total_s': 513.1509926319122, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 513.1509926319122, 'timesteps_since_restore': 0, 'iterations_since_restore': 90, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.4625, 'ram_util_percent': 25.725}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.314362121205177, 'cur_kl_coeff': 0.00037584734091069557, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.890372231186078, 'policy_loss': 0.006568586583980309, 'vf_loss': 9.88379494041525, 'vf_explained_var': -0.9404938628596644, 'kl': 0.023197053976041555, 'entropy': 0.5921289309058139, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 364455, 'num_env_steps_trained': 364455, 'num_agent_steps_sampled': 364455, 'num_agent_steps_trained': 364455}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 364455, 'num_agent_steps_trained': 364455, 'num_env_steps_sampled': 364455, 'num_env_steps_trained': 364455, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 364455, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 364455, 'timers': {'training_iteration_time_ms': 5845.776, 'load_time_ms': 10.292, 'load_throughput': 389127.97, 'learn_time_ms': 4712.268, 'learn_throughput': 849.909, 'synch_weights_time_ms': 2.993}, 'counters': {'num_env_steps_sampled': 364455, 'num_env_steps_trained': 364455, 'num_agent_steps_sampled': 364455, 'num_agent_steps_trained': 364455}, 'done': False, 'episodes_total': 126, 'training_iteration': 91, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-00', 'timestamp': 1669852980, 'time_this_iter_s': 6.388113498687744, 'time_total_s': 519.5391061306, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 519.5391061306, 'timesteps_since_restore': 0, 'iterations_since_restore': 91, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 34.44444444444444, 'ram_util_percent': 26.5}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 20.349021290450967, 'cur_kl_coeff': 0.0005637710113660432, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.904642950078493, 'policy_loss': -0.015244643624511457, 'vf_loss': 9.919874162571405, 'vf_explained_var': -1.0, 'kl': 0.023841145986915207, 'entropy': 0.6890904454133844, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 368460, 'num_env_steps_trained': 368460, 'num_agent_steps_sampled': 368460, 'num_agent_steps_trained': 368460}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 368460, 'num_agent_steps_trained': 368460, 'num_env_steps_sampled': 368460, 'num_env_steps_trained': 368460, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 368460, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 368460, 'timers': {'training_iteration_time_ms': 5850.923, 'load_time_ms': 10.541, 'load_throughput': 379959.23, 'learn_time_ms': 4708.326, 'learn_throughput': 850.621, 'synch_weights_time_ms': 3.038}, 'counters': {'num_env_steps_sampled': 368460, 'num_env_steps_trained': 368460, 'num_agent_steps_sampled': 368460, 'num_agent_steps_trained': 368460}, 'done': False, 'episodes_total': 126, 'training_iteration': 92, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-05', 'timestamp': 1669852985, 'time_this_iter_s': 5.767786026000977, 'time_total_s': 525.306892156601, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 525.306892156601, 'timesteps_since_restore': 0, 'iterations_since_restore': 92, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 22.111111111111107, 'ram_util_percent': 27.200000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 131.5463183076271, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.146848652183369, 'policy_loss': 0.009786869325394671, 'vf_loss': 9.137053634274391, 'vf_explained_var': -0.19314014680923955, 'kl': 0.009634136427947474, 'entropy': 0.6671274542167622, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 372465, 'num_env_steps_trained': 372465, 'num_agent_steps_sampled': 372465, 'num_agent_steps_trained': 372465}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 372465, 'num_agent_steps_trained': 372465, 'num_env_steps_sampled': 372465, 'num_env_steps_trained': 372465, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 372465, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 372465, 'timers': {'training_iteration_time_ms': 5860.876, 'load_time_ms': 11.053, 'load_throughput': 362336.015, 'learn_time_ms': 4707.399, 'learn_throughput': 850.788, 'synch_weights_time_ms': 3.009}, 'counters': {'num_env_steps_sampled': 372465, 'num_env_steps_trained': 372465, 'num_agent_steps_sampled': 372465, 'num_agent_steps_trained': 372465}, 'done': False, 'episodes_total': 126, 'training_iteration': 93, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-11', 'timestamp': 1669852991, 'time_this_iter_s': 5.838120698928833, 'time_total_s': 531.1450128555298, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 531.1450128555298, 'timesteps_since_restore': 0, 'iterations_since_restore': 93, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.4625, 'ram_util_percent': 27.4875}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.9424045905631075, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.537519632103622, 'policy_loss': 0.020520727228253117, 'vf_loss': 8.516992292096537, 'vf_explained_var': -0.7737938777092964, 'kl': 0.007800146161025362, 'entropy': 0.4963422442315727, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 376470, 'num_env_steps_trained': 376470, 'num_agent_steps_sampled': 376470, 'num_agent_steps_trained': 376470}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 376470, 'num_agent_steps_trained': 376470, 'num_env_steps_sampled': 376470, 'num_env_steps_trained': 376470, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 376470, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 376470, 'timers': {'training_iteration_time_ms': 5873.258, 'load_time_ms': 10.738, 'load_throughput': 372980.581, 'learn_time_ms': 4720.242, 'learn_throughput': 848.474, 'synch_weights_time_ms': 2.997}, 'counters': {'num_env_steps_sampled': 376470, 'num_env_steps_trained': 376470, 'num_agent_steps_sampled': 376470, 'num_agent_steps_trained': 376470}, 'done': False, 'episodes_total': 126, 'training_iteration': 94, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-17', 'timestamp': 1669852997, 'time_this_iter_s': 5.745294809341431, 'time_total_s': 536.8903076648712, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 536.8903076648712, 'timesteps_since_restore': 0, 'iterations_since_restore': 94, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.55, 'ram_util_percent': 27.5375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 275.5641082678591, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.029545171030106, 'policy_loss': -0.01566538099319704, 'vf_loss': 8.045200833197564, 'vf_explained_var': 0.1540905991549133, 'kl': 0.011506305946866838, 'entropy': 0.6735093759593144, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 380475, 'num_env_steps_trained': 380475, 'num_agent_steps_sampled': 380475, 'num_agent_steps_trained': 380475}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 380475, 'num_agent_steps_trained': 380475, 'num_env_steps_sampled': 380475, 'num_env_steps_trained': 380475, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 380475, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 380475, 'timers': {'training_iteration_time_ms': 5869.099, 'load_time_ms': 10.799, 'load_throughput': 370881.502, 'learn_time_ms': 4720.97, 'learn_throughput': 848.343, 'synch_weights_time_ms': 3.004}, 'counters': {'num_env_steps_sampled': 380475, 'num_env_steps_trained': 380475, 'num_agent_steps_sampled': 380475, 'num_agent_steps_trained': 380475}, 'done': False, 'episodes_total': 126, 'training_iteration': 95, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-23', 'timestamp': 1669853003, 'time_this_iter_s': 5.8780152797698975, 'time_total_s': 542.7683229446411, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 542.7683229446411, 'timesteps_since_restore': 0, 'iterations_since_restore': 95, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.644444444444442, 'ram_util_percent': 25.855555555555554}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.9449827018844825, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.906417880519744, 'policy_loss': 0.019721661952714766, 'vf_loss': 9.886691036019274, 'vf_explained_var': -0.08056553185627024, 'kl': 0.006111617631608856, 'entropy': 0.6041562342515556, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 384480, 'num_env_steps_trained': 384480, 'num_agent_steps_sampled': 384480, 'num_agent_steps_trained': 384480}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 384480, 'num_agent_steps_trained': 384480, 'num_env_steps_sampled': 384480, 'num_env_steps_trained': 384480, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 384480, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 384480, 'timers': {'training_iteration_time_ms': 5865.885, 'load_time_ms': 10.814, 'load_throughput': 370346.742, 'learn_time_ms': 4717.143, 'learn_throughput': 849.031, 'synch_weights_time_ms': 2.971}, 'counters': {'num_env_steps_sampled': 384480, 'num_env_steps_trained': 384480, 'num_agent_steps_sampled': 384480, 'num_agent_steps_trained': 384480}, 'done': False, 'episodes_total': 126, 'training_iteration': 96, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-29', 'timestamp': 1669853009, 'time_this_iter_s': 5.723403215408325, 'time_total_s': 548.4917261600494, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 548.4917261600494, 'timesteps_since_restore': 0, 'iterations_since_restore': 96, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.7625, 'ram_util_percent': 25.9125}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.6608566601269987, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.939996669112995, 'policy_loss': 0.02225700565163166, 'vf_loss': 9.917731641953992, 'vf_explained_var': 0.07942483354640263, 'kl': 0.009502531958183506, 'entropy': 0.38707938175047596, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 388485, 'num_env_steps_trained': 388485, 'num_agent_steps_sampled': 388485, 'num_agent_steps_trained': 388485}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 422.857380989448, 'episode_reward_mean': 1247.5231436982529, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [422.857380989448, 1417.2433098581835, 1375.7349525906632, 1316.0747396589293, 1333.4103396097767, 1345.937952546265, 1288.6914836933108, 1297.3611283839327, 1289.4348894355262, 1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.4302414141447957, 'mean_inference_ms': 1.1981603289210676, 'mean_action_processing_ms': 0.06914488499741504, 'mean_env_wait_ms': 0.320874260832614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 388485, 'num_agent_steps_trained': 388485, 'num_env_steps_sampled': 388485, 'num_env_steps_trained': 388485, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 388485, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 388485, 'timers': {'training_iteration_time_ms': 5867.876, 'load_time_ms': 10.778, 'load_throughput': 371591.168, 'learn_time_ms': 4709.715, 'learn_throughput': 850.37, 'synch_weights_time_ms': 2.936}, 'counters': {'num_env_steps_sampled': 388485, 'num_env_steps_trained': 388485, 'num_agent_steps_sampled': 388485, 'num_agent_steps_trained': 388485}, 'done': False, 'episodes_total': 126, 'training_iteration': 97, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-35', 'timestamp': 1669853015, 'time_this_iter_s': 5.905504465103149, 'time_total_s': 554.3972306251526, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 554.3972306251526, 'timesteps_since_restore': 0, 'iterations_since_restore': 97, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.6375, 'ram_util_percent': 26.2875}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.601001585851754, 'cur_kl_coeff': 0.0008456565170490651, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.869119042222218, 'policy_loss': -0.006097616784034237, 'vf_loss': 9.87521583905784, 'vf_explained_var': -0.5630662590585729, 'kl': 0.0009782690874853108, 'entropy': 0.5688951707014474, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 392490, 'num_env_steps_trained': 392490, 'num_agent_steps_sampled': 392490, 'num_agent_steps_trained': 392490}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 392490, 'num_agent_steps_trained': 392490, 'num_env_steps_sampled': 392490, 'num_env_steps_trained': 392490, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 392490, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 392490, 'timers': {'training_iteration_time_ms': 5871.038, 'load_time_ms': 10.75, 'load_throughput': 372564.485, 'learn_time_ms': 4704.983, 'learn_throughput': 851.225, 'synch_weights_time_ms': 2.91}, 'counters': {'num_env_steps_sampled': 392490, 'num_env_steps_trained': 392490, 'num_agent_steps_sampled': 392490, 'num_agent_steps_trained': 392490}, 'done': False, 'episodes_total': 135, 'training_iteration': 98, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-40', 'timestamp': 1669853020, 'time_this_iter_s': 5.765946388244629, 'time_total_s': 560.1631770133972, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 560.1631770133972, 'timesteps_since_restore': 0, 'iterations_since_restore': 98, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.35, 'ram_util_percent': 26.775}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 23.73480352176133, 'cur_kl_coeff': 0.00042282825852453255, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.554220092424782, 'policy_loss': 0.0026991359248597136, 'vf_loss': 9.55151699537872, 'vf_explained_var': -0.39821537495941245, 'kl': 0.009383818622613808, 'entropy': 0.6245316857932717, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 396495, 'num_env_steps_trained': 396495, 'num_agent_steps_sampled': 396495, 'num_agent_steps_trained': 396495}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 396495, 'num_agent_steps_trained': 396495, 'num_env_steps_sampled': 396495, 'num_env_steps_trained': 396495, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 396495, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 396495, 'timers': {'training_iteration_time_ms': 5874.308, 'load_time_ms': 10.777, 'load_throughput': 371641.317, 'learn_time_ms': 4708.649, 'learn_throughput': 850.562, 'synch_weights_time_ms': 2.879}, 'counters': {'num_env_steps_sampled': 396495, 'num_env_steps_trained': 396495, 'num_agent_steps_sampled': 396495, 'num_agent_steps_trained': 396495}, 'done': False, 'episodes_total': 135, 'training_iteration': 99, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-46', 'timestamp': 1669853026, 'time_this_iter_s': 5.78269624710083, 'time_total_s': 565.945873260498, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 565.945873260498, 'timesteps_since_restore': 0, 'iterations_since_restore': 99, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.855555555555554, 'ram_util_percent': 27.17777777777778}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.120702845026909, 'cur_kl_coeff': 0.00042282825852453255, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.920977665275656, 'policy_loss': 0.02589511741803939, 'vf_loss': 9.895081922059418, 'vf_explained_var': 0.6669450721433086, 'kl': 0.0016392439405257646, 'entropy': 0.5001121772232876, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 400500, 'num_env_steps_trained': 400500, 'num_agent_steps_sampled': 400500, 'num_agent_steps_trained': 400500}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 400500, 'num_agent_steps_trained': 400500, 'num_env_steps_sampled': 400500, 'num_env_steps_trained': 400500, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 400500, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 400500, 'timers': {'training_iteration_time_ms': 5833.707, 'load_time_ms': 10.365, 'load_throughput': 386390.847, 'learn_time_ms': 4679.079, 'learn_throughput': 855.938, 'synch_weights_time_ms': 2.909}, 'counters': {'num_env_steps_sampled': 400500, 'num_env_steps_trained': 400500, 'num_agent_steps_sampled': 400500, 'num_agent_steps_trained': 400500}, 'done': False, 'episodes_total': 135, 'training_iteration': 100, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-52', 'timestamp': 1669853032, 'time_this_iter_s': 5.600078105926514, 'time_total_s': 571.5459513664246, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 571.5459513664246, 'timesteps_since_restore': 0, 'iterations_since_restore': 100, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.475, 'ram_util_percent': 27.575000000000003}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 223.18499508455236, 'cur_kl_coeff': 0.00021141412926226627, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 5.632264605813449, 'policy_loss': 0.005401408399945946, 'vf_loss': 5.626860465670145, 'vf_explained_var': -0.14601497586055467, 'kl': 0.012935267614901625, 'entropy': 0.4927100000842925, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 404505, 'num_env_steps_trained': 404505, 'num_agent_steps_sampled': 404505, 'num_agent_steps_trained': 404505}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 404505, 'num_agent_steps_trained': 404505, 'num_env_steps_sampled': 404505, 'num_env_steps_trained': 404505, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 404505, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 404505, 'timers': {'training_iteration_time_ms': 5772.166, 'load_time_ms': 10.298, 'load_throughput': 388900.947, 'learn_time_ms': 4628.357, 'learn_throughput': 865.318, 'synch_weights_time_ms': 2.894}, 'counters': {'num_env_steps_sampled': 404505, 'num_env_steps_trained': 404505, 'num_agent_steps_sampled': 404505, 'num_agent_steps_trained': 404505}, 'done': False, 'episodes_total': 135, 'training_iteration': 101, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-03-58', 'timestamp': 1669853038, 'time_this_iter_s': 5.769939422607422, 'time_total_s': 577.315890789032, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 577.315890789032, 'timesteps_since_restore': 0, 'iterations_since_restore': 101, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.9375, 'ram_util_percent': 28.125}}\n",
      "Checkpoint saved to /home/codespace/ray_results/PPO_EPANETEnv_2022-11-30_23-54-074nspqvxo/checkpoint_000101\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 17.685655633057717, 'cur_kl_coeff': 0.00021141412926226627, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.443122629965504, 'policy_loss': 0.0015195794764064974, 'vf_loss': 9.441601922435146, 'vf_explained_var': -0.6785779525515854, 'kl': 0.00553157502958345, 'entropy': 0.6559953335792787, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 408510, 'num_env_steps_trained': 408510, 'num_agent_steps_sampled': 408510, 'num_agent_steps_trained': 408510}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 408510, 'num_agent_steps_trained': 408510, 'num_env_steps_sampled': 408510, 'num_env_steps_trained': 408510, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 408510, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 408510, 'timers': {'training_iteration_time_ms': 5775.251, 'load_time_ms': 9.994, 'load_throughput': 400753.582, 'learn_time_ms': 4634.024, 'learn_throughput': 864.26, 'synch_weights_time_ms': 2.863}, 'counters': {'num_env_steps_sampled': 408510, 'num_env_steps_trained': 408510, 'num_agent_steps_sampled': 408510, 'num_agent_steps_trained': 408510}, 'done': False, 'episodes_total': 135, 'training_iteration': 102, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-03', 'timestamp': 1669853043, 'time_this_iter_s': 5.79793906211853, 'time_total_s': 583.1138298511505, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 583.1138298511505, 'timesteps_since_restore': 0, 'iterations_since_restore': 102, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 25.400000000000002, 'ram_util_percent': 26.3125}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.4072633144035134, 'cur_kl_coeff': 0.00021141412926226627, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.923813157440513, 'policy_loss': 0.024426183000367176, 'vf_loss': 9.899386204955398, 'vf_explained_var': 0.4749440373912934, 'kl': 0.0039038952069100573, 'entropy': 0.6097841326908399, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 412515, 'num_env_steps_trained': 412515, 'num_agent_steps_sampled': 412515, 'num_agent_steps_trained': 412515}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 710.4440148001396, 'episode_reward_mean': 1227.521274526202, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1368.4928822232143, 1560.4311061152555, 1537.8476691946269, 1531.4840107777975, 1526.1643260776632, 1537.6758146294176, 1544.9346302168956, 1549.6434414614137, 1531.1226235063027, 1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43065798934434574, 'mean_inference_ms': 1.197946568919265, 'mean_action_processing_ms': 0.06910909922771805, 'mean_env_wait_ms': 0.320684798299613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 412515, 'num_agent_steps_trained': 412515, 'num_env_steps_sampled': 412515, 'num_env_steps_trained': 412515, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 412515, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 412515, 'timers': {'training_iteration_time_ms': 5785.605, 'load_time_ms': 9.55, 'load_throughput': 419359.198, 'learn_time_ms': 4648.853, 'learn_throughput': 861.503, 'synch_weights_time_ms': 2.892}, 'counters': {'num_env_steps_sampled': 412515, 'num_env_steps_trained': 412515, 'num_agent_steps_sampled': 412515, 'num_agent_steps_trained': 412515}, 'done': False, 'episodes_total': 135, 'training_iteration': 103, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-09', 'timestamp': 1669853049, 'time_this_iter_s': 5.940922975540161, 'time_total_s': 589.0547528266907, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 589.0547528266907, 'timesteps_since_restore': 0, 'iterations_since_restore': 103, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.725, 'ram_util_percent': 26.112499999999997}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m   warnings.warn(errmssg.value.decode())\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m /home/codespace/.python/current/lib/python3.10/site-packages/epyt/epanet.py:11809: UserWarning: WARNING: System has negative pressures.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m   warnings.warn(errmssg.value.decode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.897827216822614, 'cur_kl_coeff': 0.00010570706463113314, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.898042997749902, 'policy_loss': 0.005145995288846955, 'vf_loss': 9.892896410214004, 'vf_explained_var': -0.9334569370233884, 'kl': 0.006113361870421623, 'entropy': 0.44526272618001506, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 416520, 'num_env_steps_trained': 416520, 'num_agent_steps_sampled': 416520, 'num_agent_steps_trained': 416520}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 416520, 'num_agent_steps_trained': 416520, 'num_env_steps_sampled': 416520, 'num_env_steps_trained': 416520, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 416520, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 416520, 'timers': {'training_iteration_time_ms': 5789.925, 'load_time_ms': 9.487, 'load_throughput': 422160.476, 'learn_time_ms': 4637.889, 'learn_throughput': 863.539, 'synch_weights_time_ms': 2.922}, 'counters': {'num_env_steps_sampled': 416520, 'num_env_steps_trained': 416520, 'num_agent_steps_sampled': 416520, 'num_agent_steps_trained': 416520}, 'done': False, 'episodes_total': 144, 'training_iteration': 104, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-15', 'timestamp': 1669853055, 'time_this_iter_s': 5.789026737213135, 'time_total_s': 594.8437795639038, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 594.8437795639038, 'timesteps_since_restore': 0, 'iterations_since_restore': 104, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 21.88888888888889, 'ram_util_percent': 26.66666666666667}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 31.007449355449086, 'cur_kl_coeff': 0.00010570706463113314, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.444781200860136, 'policy_loss': -0.02298902431402796, 'vf_loss': 9.467767499082832, 'vf_explained_var': -1.0, 'kl': 0.025916401292695564, 'entropy': 0.685434679831228, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 420525, 'num_env_steps_trained': 420525, 'num_agent_steps_sampled': 420525, 'num_agent_steps_trained': 420525}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 420525, 'num_agent_steps_trained': 420525, 'num_env_steps_sampled': 420525, 'num_env_steps_trained': 420525, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 420525, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 420525, 'timers': {'training_iteration_time_ms': 5794.281, 'load_time_ms': 9.418, 'load_throughput': 425242.579, 'learn_time_ms': 4639.727, 'learn_throughput': 863.197, 'synch_weights_time_ms': 2.903}, 'counters': {'num_env_steps_sampled': 420525, 'num_env_steps_trained': 420525, 'num_agent_steps_sampled': 420525, 'num_agent_steps_trained': 420525}, 'done': False, 'episodes_total': 144, 'training_iteration': 105, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-21', 'timestamp': 1669853061, 'time_this_iter_s': 5.921488285064697, 'time_total_s': 600.7652678489685, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 600.7652678489685, 'timesteps_since_restore': 0, 'iterations_since_restore': 105, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.8125, 'ram_util_percent': 27.037499999999998}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 351.31487708521144, 'cur_kl_coeff': 0.00015856059694669967, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.50524394230176, 'policy_loss': 0.013757835469028402, 'vf_loss': 8.491482578810825, 'vf_explained_var': 0.15879104579648665, 'kl': 0.02209324889507925, 'entropy': 0.6574086932084894, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 424530, 'num_env_steps_trained': 424530, 'num_agent_steps_sampled': 424530, 'num_agent_steps_trained': 424530}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 424530, 'num_agent_steps_trained': 424530, 'num_env_steps_sampled': 424530, 'num_env_steps_trained': 424530, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 424530, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 424530, 'timers': {'training_iteration_time_ms': 5790.805, 'load_time_ms': 9.777, 'load_throughput': 409643.95, 'learn_time_ms': 4637.338, 'learn_throughput': 863.642, 'synch_weights_time_ms': 2.935}, 'counters': {'num_env_steps_sampled': 424530, 'num_env_steps_trained': 424530, 'num_agent_steps_sampled': 424530, 'num_agent_steps_trained': 424530}, 'done': False, 'episodes_total': 144, 'training_iteration': 106, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-27', 'timestamp': 1669853067, 'time_this_iter_s': 5.6879682540893555, 'time_total_s': 606.4532361030579, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 606.4532361030579, 'timesteps_since_restore': 0, 'iterations_since_restore': 106, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.05, 'ram_util_percent': 27.3375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.922732993075123, 'cur_kl_coeff': 0.00023784089542004943, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.884185738204629, 'policy_loss': 0.012761699368235886, 'vf_loss': 9.871420504457207, 'vf_explained_var': -0.9375814212906746, 'kl': 0.01485232689772525, 'entropy': 0.45726575386780566, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 428535, 'num_env_steps_trained': 428535, 'num_agent_steps_sampled': 428535, 'num_agent_steps_trained': 428535}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 428535, 'num_agent_steps_trained': 428535, 'num_env_steps_sampled': 428535, 'num_env_steps_trained': 428535, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 428535, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 428535, 'timers': {'training_iteration_time_ms': 5774.238, 'load_time_ms': 10.329, 'load_throughput': 387732.203, 'learn_time_ms': 4626.08, 'learn_throughput': 865.744, 'synch_weights_time_ms': 2.955}, 'counters': {'num_env_steps_sampled': 428535, 'num_env_steps_trained': 428535, 'num_agent_steps_sampled': 428535, 'num_agent_steps_trained': 428535}, 'done': False, 'episodes_total': 144, 'training_iteration': 107, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-33', 'timestamp': 1669853073, 'time_this_iter_s': 5.74025821685791, 'time_total_s': 612.1934943199158, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 612.1934943199158, 'timesteps_since_restore': 0, 'iterations_since_restore': 107, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.275, 'ram_util_percent': 27.637500000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 240.61277514307568, 'cur_kl_coeff': 0.00023784089542004943, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 7.9825580694342175, 'policy_loss': -0.016410562285893066, 'vf_loss': 7.998958020569176, 'vf_explained_var': -0.959030536297829, 'kl': 0.04462146895461464, 'entropy': 0.5765214815735817, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 432540, 'num_env_steps_trained': 432540, 'num_agent_steps_sampled': 432540, 'num_agent_steps_trained': 432540}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 432540, 'num_agent_steps_trained': 432540, 'num_env_steps_sampled': 432540, 'num_env_steps_trained': 432540, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 432540, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 432540, 'timers': {'training_iteration_time_ms': 5793.921, 'load_time_ms': 10.389, 'load_throughput': 385518.269, 'learn_time_ms': 4639.07, 'learn_throughput': 863.32, 'synch_weights_time_ms': 2.973}, 'counters': {'num_env_steps_sampled': 432540, 'num_env_steps_trained': 432540, 'num_agent_steps_sampled': 432540, 'num_agent_steps_trained': 432540}, 'done': False, 'episodes_total': 144, 'training_iteration': 108, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-39', 'timestamp': 1669853079, 'time_this_iter_s': 5.962121486663818, 'time_total_s': 618.1556158065796, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 618.1556158065796, 'timesteps_since_restore': 0, 'iterations_since_restore': 108, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 22.333333333333336, 'ram_util_percent': 27.044444444444444}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.5207964211321805, 'cur_kl_coeff': 0.00035676134313007436, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.863515641612391, 'policy_loss': 0.019445844565928783, 'vf_loss': 9.844065761566162, 'vf_explained_var': -0.06549810876128494, 'kl': 0.011361452409494963, 'entropy': 0.6864051573379065, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 436545, 'num_env_steps_trained': 436545, 'num_agent_steps_sampled': 436545, 'num_agent_steps_trained': 436545}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 436545, 'num_agent_steps_trained': 436545, 'num_env_steps_sampled': 436545, 'num_env_steps_trained': 436545, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 436545, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 436545, 'timers': {'training_iteration_time_ms': 5785.115, 'load_time_ms': 10.488, 'load_throughput': 381873.325, 'learn_time_ms': 4627.824, 'learn_throughput': 865.417, 'synch_weights_time_ms': 3.084}, 'counters': {'num_env_steps_sampled': 436545, 'num_env_steps_trained': 436545, 'num_agent_steps_sampled': 436545, 'num_agent_steps_trained': 436545}, 'done': False, 'episodes_total': 144, 'training_iteration': 109, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-44', 'timestamp': 1669853084, 'time_this_iter_s': 5.698696851730347, 'time_total_s': 623.8543126583099, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 623.8543126583099, 'timesteps_since_restore': 0, 'iterations_since_restore': 109, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.637500000000003, 'ram_util_percent': 26.075000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.182235614561115, 'cur_kl_coeff': 0.00035676134313007436, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.93585843527189, 'policy_loss': 0.022216629991007427, 'vf_loss': 9.91363196321713, 'vf_explained_var': 0.022056354886742048, 'kl': 0.02759768525643575, 'entropy': 0.6385286185049242, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 440550, 'num_env_steps_trained': 440550, 'num_agent_steps_sampled': 440550, 'num_agent_steps_trained': 440550}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1153.8392945527414, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1540.6396038829294, 1409.3643889672062, 1452.5116241752046, 1407.5241611333672, 1255.814457758882, 1416.9685350296018, 1527.811733850628, 1449.3078164503506, 1459.2056738559181, 1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43091557740017605, 'mean_inference_ms': 1.1978410335500491, 'mean_action_processing_ms': 0.06907515222748509, 'mean_env_wait_ms': 0.3205686719185462, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 440550, 'num_agent_steps_trained': 440550, 'num_env_steps_sampled': 440550, 'num_env_steps_trained': 440550, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 440550, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 440550, 'timers': {'training_iteration_time_ms': 5808.365, 'load_time_ms': 10.828, 'load_throughput': 369885.181, 'learn_time_ms': 4633.198, 'learn_throughput': 864.414, 'synch_weights_time_ms': 3.064}, 'counters': {'num_env_steps_sampled': 440550, 'num_env_steps_trained': 440550, 'num_agent_steps_sampled': 440550, 'num_agent_steps_trained': 440550}, 'done': False, 'episodes_total': 144, 'training_iteration': 110, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-50', 'timestamp': 1669853090, 'time_this_iter_s': 5.832933187484741, 'time_total_s': 629.6872458457947, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 629.6872458457947, 'timesteps_since_restore': 0, 'iterations_since_restore': 110, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.037499999999998, 'ram_util_percent': 26.200000000000003}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.865521742699928, 'cur_kl_coeff': 0.0005351420146951112, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.789398347177814, 'policy_loss': -0.020251150224958697, 'vf_loss': 9.809646262917468, 'vf_explained_var': -0.733133307515934, 'kl': 0.00607833565252562, 'entropy': 0.5310928999256063, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 444555, 'num_env_steps_trained': 444555, 'num_agent_steps_sampled': 444555, 'num_agent_steps_trained': 444555}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 444555, 'num_agent_steps_trained': 444555, 'num_env_steps_sampled': 444555, 'num_env_steps_trained': 444555, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 444555, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 444555, 'timers': {'training_iteration_time_ms': 5789.909, 'load_time_ms': 10.85, 'load_throughput': 369108.189, 'learn_time_ms': 4614.03, 'learn_throughput': 868.005, 'synch_weights_time_ms': 3.075}, 'counters': {'num_env_steps_sampled': 444555, 'num_env_steps_trained': 444555, 'num_agent_steps_sampled': 444555, 'num_agent_steps_trained': 444555}, 'done': False, 'episodes_total': 153, 'training_iteration': 111, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-04-56', 'timestamp': 1669853096, 'time_this_iter_s': 5.587714195251465, 'time_total_s': 635.2749600410461, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 635.2749600410461, 'timesteps_since_restore': 0, 'iterations_since_restore': 111, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 19.9625, 'ram_util_percent': 26.462500000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 291.29760918109525, 'cur_kl_coeff': 0.0005351420146951112, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 8.771573052867767, 'policy_loss': -0.011673270307621489, 'vf_loss': 8.783245006556152, 'vf_explained_var': -1.0, 'kl': 0.002496281498728834, 'entropy': 0.6870050448243336, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 448560, 'num_env_steps_trained': 448560, 'num_agent_steps_sampled': 448560, 'num_agent_steps_trained': 448560}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 448560, 'num_agent_steps_trained': 448560, 'num_env_steps_sampled': 448560, 'num_env_steps_trained': 448560, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 448560, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 448560, 'timers': {'training_iteration_time_ms': 5793.218, 'load_time_ms': 10.775, 'load_throughput': 371702.171, 'learn_time_ms': 4605.271, 'learn_throughput': 869.656, 'synch_weights_time_ms': 3.064}, 'counters': {'num_env_steps_sampled': 448560, 'num_env_steps_trained': 448560, 'num_agent_steps_sampled': 448560, 'num_agent_steps_trained': 448560}, 'done': False, 'episodes_total': 153, 'training_iteration': 112, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-02', 'timestamp': 1669853102, 'time_this_iter_s': 5.831155300140381, 'time_total_s': 641.1061153411865, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 641.1061153411865, 'timesteps_since_restore': 0, 'iterations_since_restore': 112, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 17.677777777777777, 'ram_util_percent': 26.633333333333333}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 9.596709467768068, 'cur_kl_coeff': 0.0002675710073475556, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.88591750975578, 'policy_loss': 0.01654121869353838, 'vf_loss': 9.869369386857556, 'vf_explained_var': -0.15953539738091088, 'kl': 0.02567699994538437, 'entropy': 0.6240537919664896, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 452565, 'num_env_steps_trained': 452565, 'num_agent_steps_sampled': 452565, 'num_agent_steps_trained': 452565}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 452565, 'num_agent_steps_trained': 452565, 'num_env_steps_sampled': 452565, 'num_env_steps_trained': 452565, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 452565, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 452565, 'timers': {'training_iteration_time_ms': 5760.75, 'load_time_ms': 10.689, 'load_throughput': 374692.742, 'learn_time_ms': 4572.697, 'learn_throughput': 875.851, 'synch_weights_time_ms': 3.051}, 'counters': {'num_env_steps_sampled': 452565, 'num_env_steps_trained': 452565, 'num_agent_steps_sampled': 452565, 'num_agent_steps_trained': 452565}, 'done': False, 'episodes_total': 153, 'training_iteration': 113, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-07', 'timestamp': 1669853107, 'time_this_iter_s': 5.616602897644043, 'time_total_s': 646.7227182388306, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 646.7227182388306, 'timesteps_since_restore': 0, 'iterations_since_restore': 113, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.1125, 'ram_util_percent': 26.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.310257250198754, 'cur_kl_coeff': 0.0004013565110213334, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.546738865554973, 'policy_loss': 0.0009442885982133048, 'vf_loss': 9.545793718932778, 'vf_explained_var': -1.0, 'kl': 0.0023383463336266066, 'entropy': 0.4832148475432268, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 456570, 'num_env_steps_trained': 456570, 'num_agent_steps_sampled': 456570, 'num_agent_steps_trained': 456570}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 456570, 'num_agent_steps_trained': 456570, 'num_env_steps_sampled': 456570, 'num_env_steps_trained': 456570, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 456570, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 456570, 'timers': {'training_iteration_time_ms': 5760.394, 'load_time_ms': 11.048, 'load_throughput': 362502.563, 'learn_time_ms': 4574.94, 'learn_throughput': 875.421, 'synch_weights_time_ms': 3.163}, 'counters': {'num_env_steps_sampled': 456570, 'num_env_steps_trained': 456570, 'num_agent_steps_sampled': 456570, 'num_agent_steps_trained': 456570}, 'done': False, 'episodes_total': 153, 'training_iteration': 114, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-13', 'timestamp': 1669853113, 'time_this_iter_s': 5.785134553909302, 'time_total_s': 652.5078527927399, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 652.5078527927399, 'timesteps_since_restore': 0, 'iterations_since_restore': 114, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 16.8, 'ram_util_percent': 26.725}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 49.75802259087883, 'cur_kl_coeff': 0.0002006782555106667, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.329245280194026, 'policy_loss': 0.00986592561327001, 'vf_loss': 9.319378694923975, 'vf_explained_var': -0.056334922839236516, 'kl': 0.0034454659452027797, 'entropy': 0.6465401239933506, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 460575, 'num_env_steps_trained': 460575, 'num_agent_steps_sampled': 460575, 'num_agent_steps_trained': 460575}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 460575, 'num_agent_steps_trained': 460575, 'num_env_steps_sampled': 460575, 'num_env_steps_trained': 460575, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 460575, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 460575, 'timers': {'training_iteration_time_ms': 5728.02, 'load_time_ms': 11.079, 'load_throughput': 361506.343, 'learn_time_ms': 4542.931, 'learn_throughput': 881.59, 'synch_weights_time_ms': 3.238}, 'counters': {'num_env_steps_sampled': 460575, 'num_env_steps_trained': 460575, 'num_agent_steps_sampled': 460575, 'num_agent_steps_trained': 460575}, 'done': False, 'episodes_total': 153, 'training_iteration': 115, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-19', 'timestamp': 1669853119, 'time_this_iter_s': 5.5994415283203125, 'time_total_s': 658.1072943210602, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 658.1072943210602, 'timesteps_since_restore': 0, 'iterations_since_restore': 115, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 17.4125, 'ram_util_percent': 26.7}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.826398055299475, 'cur_kl_coeff': 0.00010033912775533335, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.936807335063975, 'policy_loss': 0.025105613758487084, 'vf_loss': 9.911701236232634, 'vf_explained_var': 0.19754466440088006, 'kl': 0.0046110752184890585, 'entropy': 0.587718589267423, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 464580, 'num_env_steps_trained': 464580, 'num_agent_steps_sampled': 464580, 'num_agent_steps_trained': 464580}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1159.6904641326237, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1389.502995617379, 1458.514105330582, 1500.6339064978536, 1432.8825733259687, 1423.752945759724, 1472.12157578534, 1492.328049110919, 1543.5959790795455, 1533.6435984653103, 1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43128918635212643, 'mean_inference_ms': 1.197960922189027, 'mean_action_processing_ms': 0.06906024187420379, 'mean_env_wait_ms': 0.32053920966114396, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 464580, 'num_agent_steps_trained': 464580, 'num_env_steps_sampled': 464580, 'num_env_steps_trained': 464580, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 464580, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 464580, 'timers': {'training_iteration_time_ms': 5746.619, 'load_time_ms': 10.785, 'load_throughput': 371349.659, 'learn_time_ms': 4561.923, 'learn_throughput': 877.919, 'synch_weights_time_ms': 3.302}, 'counters': {'num_env_steps_sampled': 464580, 'num_env_steps_trained': 464580, 'num_agent_steps_sampled': 464580, 'num_agent_steps_trained': 464580}, 'done': False, 'episodes_total': 153, 'training_iteration': 116, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-25', 'timestamp': 1669853125, 'time_this_iter_s': 5.8765645027160645, 'time_total_s': 663.9838588237762, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 663.9838588237762, 'timesteps_since_restore': 0, 'iterations_since_restore': 116, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.3875, 'ram_util_percent': 26.6125}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7936)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m EPANET version 20200 loaded (EPyT version 1.0.2).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m Input File BUILDING.inp loaded successfully.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7943)\u001b[0m \n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.9889796457695352, 'cur_kl_coeff': 5.0169563877666673e-05, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.88527819725775, 'policy_loss': -0.003082742686233213, 'vf_loss': 9.888358533510598, 'vf_explained_var': -1.0, 'kl': 0.04842264830413715, 'entropy': 0.48829602671246375, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 468585, 'num_env_steps_trained': 468585, 'num_agent_steps_sampled': 468585, 'num_agent_steps_trained': 468585}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 468585, 'num_agent_steps_trained': 468585, 'num_env_steps_sampled': 468585, 'num_env_steps_trained': 468585, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 468585, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 468585, 'timers': {'training_iteration_time_ms': 5739.226, 'load_time_ms': 10.23, 'load_throughput': 391489.487, 'learn_time_ms': 4556.095, 'learn_throughput': 879.042, 'synch_weights_time_ms': 3.488}, 'counters': {'num_env_steps_sampled': 468585, 'num_env_steps_trained': 468585, 'num_agent_steps_sampled': 468585, 'num_agent_steps_trained': 468585}, 'done': False, 'episodes_total': 162, 'training_iteration': 117, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-30', 'timestamp': 1669853130, 'time_this_iter_s': 5.6656928062438965, 'time_total_s': 669.6495516300201, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 669.6495516300201, 'timesteps_since_restore': 0, 'iterations_since_restore': 117, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 18.733333333333334, 'ram_util_percent': 25.711111111111112}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 167.257759539078, 'cur_kl_coeff': 7.525434581650004e-05, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.05866139370908, 'policy_loss': -0.013964532619161953, 'vf_loss': 9.072625501694217, 'vf_explained_var': -1.0, 'kl': 0.006169945022498647, 'entropy': 0.5266925628787728, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 472590, 'num_env_steps_trained': 472590, 'num_agent_steps_sampled': 472590, 'num_agent_steps_trained': 472590}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 472590, 'num_agent_steps_trained': 472590, 'num_env_steps_sampled': 472590, 'num_env_steps_trained': 472590, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 472590, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 472590, 'timers': {'training_iteration_time_ms': 5725.523, 'load_time_ms': 10.62, 'load_throughput': 377100.937, 'learn_time_ms': 4555.805, 'learn_throughput': 879.098, 'synch_weights_time_ms': 3.465}, 'counters': {'num_env_steps_sampled': 472590, 'num_env_steps_trained': 472590, 'num_agent_steps_sampled': 472590, 'num_agent_steps_trained': 472590}, 'done': False, 'episodes_total': 162, 'training_iteration': 118, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-36', 'timestamp': 1669853136, 'time_this_iter_s': 5.8257527351379395, 'time_total_s': 675.4753043651581, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 675.4753043651581, 'timesteps_since_restore': 0, 'iterations_since_restore': 118, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 17.474999999999998, 'ram_util_percent': 25.7125}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 16.736434930050244, 'cur_kl_coeff': 7.525434581650004e-05, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.888533553256783, 'policy_loss': 0.020313854980212386, 'vf_loss': 9.868219074126213, 'vf_explained_var': 0.100333147920588, 'kl': 0.00884385909098267, 'entropy': 0.49620029375117314, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 476595, 'num_env_steps_trained': 476595, 'num_agent_steps_sampled': 476595, 'num_agent_steps_trained': 476595}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 476595, 'num_agent_steps_trained': 476595, 'num_env_steps_sampled': 476595, 'num_env_steps_trained': 476595, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 476595, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 476595, 'timers': {'training_iteration_time_ms': 5749.055, 'load_time_ms': 11.009, 'load_throughput': 363782.961, 'learn_time_ms': 4579.864, 'learn_throughput': 874.48, 'synch_weights_time_ms': 3.363}, 'counters': {'num_env_steps_sampled': 476595, 'num_env_steps_trained': 476595, 'num_agent_steps_sampled': 476595, 'num_agent_steps_trained': 476595}, 'done': False, 'episodes_total': 162, 'training_iteration': 119, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-42', 'timestamp': 1669853142, 'time_this_iter_s': 5.930432319641113, 'time_total_s': 681.4057366847992, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 681.4057366847992, 'timesteps_since_restore': 0, 'iterations_since_restore': 119, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.025, 'ram_util_percent': 25.8375}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'num_recreated_workers': 0, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 14.009629533047317, 'cur_kl_coeff': 7.525434581650004e-05, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.672231276317309, 'policy_loss': 0.010892758350218495, 'vf_loss': 9.661335057084278, 'vf_explained_var': -1.0, 'kl': 0.04589325136143867, 'entropy': 0.42437831799910275, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0}}, 'num_env_steps_sampled': 480600, 'num_env_steps_trained': 480600, 'num_agent_steps_sampled': 480600, 'num_agent_steps_trained': 480600}, 'sampler_results': {'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': 1565.5369995543258, 'episode_reward_min': 670.7883689994184, 'episode_reward_mean': 1162.6009188927562, 'episode_len_mean': 2880.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1505.2563496392763, 1110.3584845993714, 1248.863571954995, 1103.559813885683, 1154.6737784676895, 1330.306529505731, 1096.306528997659, 1050.180599194701, 1254.6528657918952, 1118.7637247624148, 1293.093174708082, 1271.900313704404, 1249.634854557453, 1243.2050025007097, 1280.738969992523, 1279.7394615053202, 1287.9933524475678, 1285.7230611240707, 1274.19302096055, 1528.2524443454165, 1539.875839566735, 1565.5369995543258, 1548.3406483640188, 1525.3922190395115, 1534.7812241323913, 1545.8040750011985, 1555.0323253841343, 1544.7526697646524, 947.4905222337785, 883.484347657547, 795.0736608443599, 967.9251041428353, 812.2629800182381, 842.337943338485, 760.6191508041114, 744.4776281212258, 714.9554227841087, 1060.3463023171275, 1028.0930671627066, 1204.3518623377984, 1319.3625331426697, 1088.6785375651618, 1103.4986174013584, 1275.2681054805205, 1071.327334425849, 1291.083944468662, 1282.3827002900373, 1281.2297774366093, 1310.7621833862374, 1287.449858830424, 1284.8864853648327, 1287.5239252083745, 1295.8625417697363, 1285.6124420036763, 1288.9922574138175, 783.6142038907616, 753.9605294624171, 804.6491407343491, 710.4440148001396, 793.4773572543171, 770.7823605002142, 801.4222212194438, 818.1803874064558, 732.8666101090906, 985.2302285121947, 1058.7627264794319, 953.2092944466813, 1085.2104150299376, 962.6866935603393, 964.3687851036847, 1074.7400838184383, 959.5201648083143, 1042.830867801918, 716.7896325625281, 673.2594970417888, 732.8609453506866, 693.5773936700614, 686.7816143354665, 733.420722518229, 682.958467484704, 729.1618648936536, 670.7883689994184, 1502.4788529112336, 1467.0127754011664, 1445.255243709814, 1502.971642376744, 1477.8110194250314, 1535.391745440767, 1533.3500820897004, 1509.8401615141197, 1530.1534302237214, 1503.466207198466, 1510.5986292508646, 1513.232012009378, 1501.4265354150589, 1514.013640824995, 1462.72903087158, 1518.597025628746, 1506.2066243901913, 1507.7514993966054], 'episode_lengths': [2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880, 2880]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.43167724909976357, 'mean_inference_ms': 1.1983218056649958, 'mean_action_processing_ms': 0.06906321596660335, 'mean_env_wait_ms': 0.3206140238660484, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 9, 'num_agent_steps_sampled': 480600, 'num_agent_steps_trained': 480600, 'num_env_steps_sampled': 480600, 'num_env_steps_trained': 480600, 'num_env_steps_sampled_this_iter': 4005, 'num_env_steps_trained_this_iter': 4005, 'timesteps_total': 480600, 'num_steps_trained_this_iter': 4005, 'agent_timesteps_total': 480600, 'timers': {'training_iteration_time_ms': 5786.19, 'load_time_ms': 11.025, 'load_throughput': 363251.964, 'learn_time_ms': 4627.165, 'learn_throughput': 865.541, 'synch_weights_time_ms': 3.365}, 'counters': {'num_env_steps_sampled': 480600, 'num_env_steps_trained': 480600, 'num_agent_steps_sampled': 480600, 'num_agent_steps_trained': 480600}, 'done': False, 'episodes_total': 162, 'training_iteration': 120, 'trial_id': 'default', 'experiment_id': '0b3b612eb6f44597b95ecfd8c30e2038', 'date': '2022-12-01_00-05-48', 'timestamp': 1669853148, 'time_this_iter_s': 6.2052717208862305, 'time_total_s': 687.6110084056854, 'pid': 7167, 'hostname': 'codespaces-8639a1', 'node_ip': '172.16.5.4', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 445, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'esc.epanet_env.EPANETEnv'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 9, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': 2880.0, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'relu', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': True, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c5c3580>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'ERROR', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'replay_mode': -1, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fa14c545c00>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1}, 'time_since_restore': 687.6110084056854, 'timesteps_since_restore': 0, 'iterations_since_restore': 120, 'warmup_time': 11.081435441970825, 'perf': {'cpu_util_percent': 20.65555555555555, 'ram_util_percent': 26.055555555555557}}\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPO\n",
    "\n",
    "from esc.epanet_env import N_SIMULATION_STEPS, EPANETEnv\n",
    "\n",
    "N_TRAINING_ITERATIONS = 1000\n",
    "# Configure the algorithm.\n",
    "config = {\n",
    "    \"env_config\": {},\n",
    "    # Use 5 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 9,\n",
    "    \"horizon\": N_SIMULATION_STEPS,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"torch\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `algo.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    # \"evaluation_config\": {\n",
    "    #     \"render_env\": True,\n",
    "    # },\n",
    "    \"log_level\": \"ERROR\"\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "algo = PPO(env=EPANETEnv, config=config)\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for i in range(N_TRAINING_ITERATIONS):\n",
    "    print(algo.train())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        checkpoint = algo.save()\n",
    "        print(f\"Checkpoint saved to {checkpoint}\")\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
